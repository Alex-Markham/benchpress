import json
from jsonschema import validate

with open('config.json') as json_file:
    conf = json.load(json_file)

# Validade cofnig.json file
with open('config.schema') as json_file:
    schema = json.load(json_file)

validate(instance=conf, schema=schema)

available_conf_ids = []
for alg, alg_conf_avail in conf["structure_learning_algorithms"].items():
    for alg_conf in alg_conf_avail:
        available_conf_ids.append(alg_conf["id"])   

for alg_conf_id in conf["plotting"]["algorithms"]:
    if alg_conf_id not in available_conf_ids:
        raise Exception(alg_conf_id + " not available")

pattern_strings = {}
pattern_strings["blip"] = "blip/alg_params=/" \
                "score_type={score_type}/" \
                "bdecatpar_chi={bdecatpar_chi}/" \
                "bdecatpar_edgepf={bdecatpar_edgepf}/" \
                "time={max_time}/" \
                "scorer.method={scorermethod}/" \
                "solver.method={solvermethod}/" \
                "indeg={indeg}/" \        
                "cores={cores}/" \
                "allocated={allocated}/" \
                "scorefunction={scorefunction}/" \
                "alpha={alpha}/" \
                "verbose={verbose}"

pattern_strings["pcalg"] = "pcalg/alg_params=/"\
               "score_type={score_type}/" \
               "bdecatpar_chi={bdecatpar_chi}/" \
               "bdecatpar_edgepf={bdecatpar_edgepf}/" \
               "alpha={alpha}"

pattern_strings["mmhc"] = "mmhc/alg_params=/"\
               "score_type={score_type}/" \
               "bdecatpar_chi={bdecatpar_chi}/" \
               "bdecatpar_edgepf={bdecatpar_edgepf}/" \
               "alpha={alpha}"

pattern_strings["tabu"] = "tabu/alg_params=/"\
               "score_type={score_type}/" \
               "bdecatpar_chi={bdecatpar_chi}/" \
               "bdecatpar_edgepf={bdecatpar_edgepf}/" \
               "score={score}/"\
               "iss={iss}/"\
               "iss.mu={issmu}/"\
               "l={l}/"\
               "k={k}/"\
               "prior={prior}/"\
               "beta={beta}"\

pattern_strings["gobnilp"] = "gobnilp/alg_params=/"\
                 "score_type={score_type}/" \
                 "bdecatpar_chi={bdecatpar_chi}/" \
                 "bdecatpar_edgepf={bdecatpar_edgepf}/" \
                 "palim={palim}" \
                 "alpha={alpha}"\
                 "prune={prune}"

pattern_strings["fges"] = "fges/alg_params=/"\
               "score_type={score_type}/" \
               "bdecatpar_chi={bdecatpar_chi}/" \
               "bdecatpar_edgepf={bdecatpar_edgepf}/" \
               "score={score}/" \
               "data-type={datatype}/"\
               "faithfulnessAssumed={faithfulnessAssumed}"

pattern_strings["itsearch"] = "itsearch/alg_params=/"\
                    "scoretype={scoretype}/"\
                    "chi={chi}/" \
                    "edgepf={edgepf}/" \
                    "am={am}/" \
                    "aw={aw}/" \
                    "map={MAP}/"\
                    "plus1it={plus1it}/"\
                    "posterior={posterior}"

pattern_strings["order_mcmc"] = "order_mcmc/alg_params=/"\
                    "scoretype={scoretype}/"\
                    "chi={chi}/" \
                    "edgepf={edgepf}/" \
                    "am={am}/" \
                    "aw={aw}/" \
                    "startspace_algorithm=/{startspace_algorithm}"

pattern_strings["mcmc_est"] = "estimation_method/"\
                  "threshold={threshold}/"\
                  "burnin={burnin}"

pattern_strings["trilearn_loglin"] = "trilearn_loglin/alg_params=/"\
                  "score_type={score_type}/"\
                  "bdecatpar_chi={bdecatpar_chi}/" \
                  "bdecatpar_edgepf={bdecatpar_edgepf}/" \
                  "alpha={alpha}/"\
                  "beta={beta}/"\
                  "radii={radii}/"\
                  "pseudo_obs={pseudo_obs}/"\
                  "M={M}/"\
                  "N={N}" 

pattern_strings["evaluation"] = "evaluation/" \
                   "score_type={score_type}/" \
                   "bdecatpar_chi={bdecatpar_chi}/" \
                   "bdecatpar_edgepf={bdecatpar_edgepf}" 

json_string = {}
json_string = {val["id"]: expand(pattern_strings["itsearch"], 
                                            scoretype=val["optional"]["scoretype"],
                                            chi=val["optional"]["chi"],
                                           edgepf=val["optional"]["edgepf"],
                                           am=val["optional"]["am"],
                                           aw=val["optional"]["aw"],
                                           MAP=val["optional"]["MAP"],
                                           plus1it=val["optional"]["plus1it"],
                                           posterior=val["optional"]["posterior"]) 
                    for val in conf["structure_learning_algorithms"]["itsearch"]}

json_string.update({val["id"]: expand(pattern_strings["fges"], score_type="bdecat",
                                           bdecatpar_chi=conf["evaluation"]["score"]["bdecatpar"]["chi"],
                                           bdecatpar_edgepf=conf["evaluation"]["score"]["bdecatpar"]["edgepf"],
                                           faithfulnessAssumed=val["faithfulnessAssumed"],
                                           datatype=val["data-type"],
                                           score=val["score"]) 
                    for val in conf["structure_learning_algorithms"]["fges"]})

json_string.update({val["id"]: expand(pattern_strings["pcalg"], score_type="bdecat",
                                           bdecatpar_chi=conf["evaluation"]["score"]["bdecatpar"]["chi"],
                                           bdecatpar_edgepf=conf["evaluation"]["score"]["bdecatpar"]["edgepf"],
                                           alpha=val["alpha"])  
                    for val in conf["structure_learning_algorithms"]["pcalg"]})

json_string.update({val["id"]: expand(pattern_strings["mmhc"], score_type="bdecat",
                                           bdecatpar_chi=conf["evaluation"]["score"]["bdecatpar"]["chi"],
                                           bdecatpar_edgepf=conf["evaluation"]["score"]["bdecatpar"]["edgepf"],
                                           alpha=val["restrict.args"]["alpha"])  
                    for val in conf["structure_learning_algorithms"]["mmhc"]} )

json_string.update({val["id"]: expand(pattern_strings["gobnilp"], score_type="bdecat",
                                                bdecatpar_chi=conf["evaluation"]["score"]["bdecatpar"]["chi"],
                                                bdecatpar_edgepf=conf["evaluation"]["score"]["bdecatpar"]["edgepf"],
                                                palim=val["palim"],
                                                alpha=val["alpha"],
                                                prune=val["prune"]
                                                )
                for val in conf["structure_learning_algorithms"]["gobnilp"]})

json_string.update({val["id"]:  expand(pattern_strings["tabu"], score_type="bdecat",
                                                    bdecatpar_chi=conf["evaluation"]["score"]["bdecatpar"]["chi"],
                                                    bdecatpar_edgepf=conf["evaluation"]["score"]["bdecatpar"]["edgepf"],
                                                    score=val["score"],
                                                    iss=val["iss"],
                                                    issmu=val["iss.mu"],
                                                    l=val["l"],
                                                    k=val["k"],
                                                    prior=val["prior"],
                                                    beta=val["beta"]
                                                    )
                for val in conf["structure_learning_algorithms"]["tabu"]})

json_string.update({val["id"]: expand(pattern_strings["trilearn_loglin"] +"/"+pattern_strings["mcmc_est"], 
                    score_type="bdecat",
                    bdecatpar_chi=conf["evaluation"]["score"]["bdecatpar"]["chi"],
                    bdecatpar_edgepf=conf["evaluation"]["score"]["bdecatpar"]["edgepf"],
                    alpha=val["alpha"],
                    beta=val["beta"],
                    N=val["N"],
                    M=val["M"],
                    pseudo_obs=val["pseudo_obs"],
                    radii=val["radii"],
                    threshold=val["threshold"],
                    burnin=val["burnin"],
                    )
               for val in conf["structure_learning_algorithms"]["trilearn_loglin"]})

json_string.update({val["id"]: expand(pattern_strings["blip"], score_type="bdecat",
                                            bdecatpar_chi=conf["evaluation"]["score"]["bdecatpar"]["chi"],
                                            bdecatpar_edgepf=conf["evaluation"]["score"]["bdecatpar"]["edgepf"],
                                            max_time=val["time"],
                                            solvermethod=val["solver.method"],
                                            scorermethod=val["scorer.method"],
                                            indeg=val["indeg"],
                                            cores=val["cores"],
                                            allocated=val["allocated"],
                                            scorefunction=val["scorefunction"],
                                            alpha=val["alpha"],
                                            verbose=val["verbose"]
                                            )
                for val in conf["structure_learning_algorithms"]["blip"]})

# This has to be the last one since it takes input strings as start space...
json_string.update({val["id"]: expand(pattern_strings["order_mcmc"]+"/"+pattern_strings["mcmc_est"], 
                                            scoretype="bdecat",
                                            chi=val["chi"],
                                            edgepf=val["edgepf"],
                                            am=val["am"],
                                            aw=val["aw"],
                                            startspace_algorithm=json_string[val["startspace"]],
                                            threshold=val["threshold"],
                                            burnin=val["burnin"],)  
                    for val in conf["structure_learning_algorithms"]["order_mcmc"] } )

def join_string_sampled_model_mcmc(algorithm):
    ret = [[[[expand(config["output_dir"] + "/result/"\        
                        "algorithm=/{json_string}/" #+ pattern_strings["mcmc_est"] + "/" + 
                        "adjmat=/{adjmat_string}/"
                        "bn=/{param_string}/"
                        "data=/"
                        "n={n}/"
                        "seed={replicate}/"
                        "legend={plot_legend}/" 
                        "result.csv",
        replicate=seed,   
        n=config["data"]["sample_sizes"][i],
        threshold=alg_conf["threshold"],
        burnin=alg_conf["burnin"],        
        json_string=json_string[alg_conf["id"]],
        plot_legend=alg_conf["plot_legend"], 
        adjmat_string=gen_adjmat_string_from_conf(config["plotting"]["models"][j]["graph"], seed, i), 
        param_string=gen_parameter_string_from_conf(config["plotting"]["models"][j]["parameters"], seed)
        )         
        for seed in replicates] 
        for i in range(len(config["data"]["sample_sizes"]))]
        for j in range(len(config["plotting"]["models"]))]
        for alg_conf in config["structure_learning_algorithms"][algorithm] if alg_conf["id"] in config["plotting"]["algorithms"]],
    return ret

def join_string_fixed_data_mcmc(algorithm):
    ret = [[expand(config["output_dir"] + "/result/"\        
                        "algorithm=/{json_string}/" #+ pattern_strings["mcmc_est"] + "/"
                        "adjmat=/"
                        "{adjmat_string}/"
                        "bn=/"\
                        "{param_string}/"
                        "data=/"
                        "generation_method=fixed/" # or standard_Sampling                        
                        "name={filename}/"
                        "n={n}/"
                        "seed={replicate}/"
                        "legend={plot_legend}/" 
                        "result.csv",
                        replicate=1,                        
                        threshold=alg_conf["threshold"],
                        burnin=alg_conf["burnin"],
                        n=None,
                        json_string=json_string[alg_conf["id"]],
                        plot_legend=alg_conf["plot_legend"],
                        adjmat_string="myadjmats/" + config["plotting"]["fixed_data"][j]["graph"],
                        param_string=None, 
                        filename=config["plotting"]["fixed_data"][j]["data"],
        )         
        for j in range(len(config["plotting"]["fixed_data"]))]
        for alg_conf in config["structure_learning_algorithms"][algorithm] if alg_conf["id"] in config["plotting"]["algorithms"]]
    return ret

def adjmat_estimate_path_mcmc(algorithm):
    ret = config["output_dir"]+"/adjmat_estimate/"\
                        "adjmat=/{adjmat}/"\
                        "bn=/{bn}/"\
                        "data=/{data}/"\
                        "algorithm=/" + pattern_strings[algorithm] + "/" + pattern_strings["mcmc_est"] + "/" \
                        "seed={replicate}/" \
                        "adjmat.csv"
    return ret

def time_path(algorithm):
    ret = config["output_dir"]+"/time/"\
                    "adjmat=/{adjmat}/"\
                    "bn=/{bn}/"\
                    "data=/{data}/"\
                    "algorithm=/" + pattern_strings[algorithm] + "/" + \
                    "seed={replicate}/" \
                    "time.txt"
    return ret

def result_path_mcmc(algorithm):
    res = config["output_dir"]+"/result/"\
            "algorithm=/" + pattern_strings[algorithm] + "/" + pattern_strings["mcmc_est"] + "/"\
            "adjmat=/{adjmat}/"\
            "bn=/{bn}/"\
            "data=/{data}/"\   
            "seed={replicate}/" \
            "legend={plot_legend}/" \        
            "result.csv"
    return res

def data_path():
    return config["output_dir"]+"/data/adjmat=/{adjmat}/bn=/{bn}/data=/{data}/seed={replicate}.csv"

def adjmat_true_path():
    return config["output_dir"]+"/adjmat/{adjmat}.csv",

def join_string_sampled_model(algorithm):
    ret = [[[[expand(config["output_dir"] + "/result/"\        
                            "algorithm=/"
                            "{alg_string}/"
                            "adjmat=/"
                            "{adjmat_string}/"
                            "bn=/"\
                            "{param_string}/"
                            "data=/"
                            "n={n}/"
                            "seed={replicate}/"
                            "legend={plot_legend}/" 
                            "result.csv",
                            replicate=seed,
                            alg_string=json_string[alg_conf["id"]],
                            n=config["data"]["sample_sizes"][i],
                            plot_legend=alg_conf["plot_legend"],
                            adjmat_string=gen_adjmat_string_from_conf(config["plotting"]["models"][j]["graph"], seed, i), 
                            param_string=gen_parameter_string_from_conf(config["plotting"]["models"][j]["parameters"], seed)
            )         
            for seed in replicates] 
            for i in range(len(config["data"]["sample_sizes"]))]
            for j in range(len(config["plotting"]["models"]))]
            for alg_conf in config["structure_learning_algorithms"][algorithm] if alg_conf["id"] in config["plotting"]["algorithms"]]
    return ret

def join_string_fixed_data(algorithm):
    ret = [[expand(config["output_dir"] + "/result/"\        
                            "algorithm=/"
                            "{alg_string}/"
                            "adjmat=/"
                            "{adjmat_string}/"
                            "bn=/"\
                            "{param_string}/"
                            "data=/"
                            "generation_method=fixed/" #or standard_Sampling                        
                            "name={filename}/"
                            "n={n}/"
                            "seed={replicate}/"
                            "legend={plot_legend}/" 
                            "result.csv",
                            replicate=1,
                            alg_string=json_string[alg_conf["id"]],
                            n=None,
                            score_type="bde",
                            bdecatpar_chi=config["evaluation"]["score"]["bdecatpar"]["chi"],
                            bdecatpar_edgepf=config["evaluation"]["score"]["bdecatpar"]["edgepf"],
                            plot_legend=alg_conf["plot_legend"],
                            adjmat_string="myadjmats/" + config["plotting"]["fixed_data"][j]["graph"],
                            param_string=None, 
                            filename=config["plotting"]["fixed_data"][j]["data"],
            )         
            for j in range(len(config["plotting"]["fixed_data"]))]
            for alg_conf in config["structure_learning_algorithms"][algorithm] if alg_conf["id"] in config["plotting"]["algorithms"]]
    return ret

def join_summaries_shell(algorithm):
    return "Rscript scripts/join_csv_files.R --algorithm "+algorithm+" --filename {output} --files {input.res} {input.fixed_res}"  \
            " && sed --in-place 's/\/seed=[0-9]\+//g' {output}" # removes the /seed={seed} :-)

def join_summaries_output(algorithm):
    return config["output_dir"] + "/"+algorithm+".csv"

def gen_model_strings_from_conf(models, seed, setup):
    """
    Generate the graphs and paremeters simulatnepusly since we do not want 
    every combiantion of graphs and paramters.
    Maybe this should be part of the setup? -No, this part belongs to the method step, 
    not the model/data simulation step.
    There are 3 steps.
    1. Specify the models.
    2. Generate data sets from the models.
    3. Run a nunmber of structure learningn algortithms on th dataset.
    """
    pass

def gen_adjmat_string_from_conf(adjmat_gen_method, seed, setup):
    with open('config.json') as json_file:
        conf = json.load(json_file)

    fixed_graphs = ["asia", "survey", "alarm", "sachs", "hepar2", "hailfinder"]
    if adjmat_gen_method == "generateDAGMaxParents":
        curconf = conf["graph_sampling_algorithms"][adjmat_gen_method]
        n_simulation_setups = len(conf["data"]["sample_sizes"])
        return expand(adjmat_gen_method + \
            "/p={p}" + 
            "/avpar={av_parents}" + 
            "/seed={seed}",
            av_parents=curconf["av_parents"][setup], 
            p=curconf["dims"][setup],
            seed=seed) 
    elif adjmat_gen_method in fixed_graphs:
        return "bn.fit_adjmats/" + adjmat_gen_method    

def gen_parameter_string_from_conf(gen_method, seed):
    with open('config.json') as json_file:
        conf = json.load(json_file)

    if gen_method == "generateBinaryBN":
        curconf = conf["parameters_sampling_algorithms"][gen_method]
        return expand(gen_method + \
                "/min={min}" + \
                "/max={max}" + \
                "/seed={seed}", 
                min=curconf["min"], 
                max=curconf["max"], 
                seed=seed)
    elif gen_method in ["asia", "survey", "hailfinder", "alarm", "sachs", "hepar2"]:
        return "bn.fit_networks/"+gen_method

def active_algorithm_files(wildcards):
    with open('config.json') as json_file:
        conf = json.load(json_file)
    algs = []

    #plotting_algconfs = [alg_conf for alg_conf in conf["plotting"]["algorithms"]]

    for alg, alg_conf_list in conf["structure_learning_algorithms"].items():     
        for alg_conf_id in conf["plotting"]["algorithms"]:
            if alg_conf_id in [ac["id"] for ac in alg_conf_list]:
                    algs.append(conf["output_dir"] + "/" + alg + ".csv")
    return algs

def alg_output_adjmat_path(algorithm):
    return config["output_dir"]+"/adjmat_estimate/{data}/"\
                "algorithm=/" + pattern_strings[algorithm] + "/" +\
                "seed={replicate}/" \
                "adjmat.csv"

def alg_output_adjvecs_path(algorithm):
    return config["output_dir"]+"/adjvecs/{data}/"\
                "algorithm=/"  + pattern_strings[algorithm] + "/"  + \
                "seed={replicate}/" \
                "adjvecs.json"

def alg_output_time_path(algorithm):
    return config["output_dir"] + "/time/{data}/"\
                "algorithm=/" + pattern_strings[algorithm] + "/" +\
                "seed={replicate}/" \
                "time.txt"

def alg_input_data():
    return config["output_dir"]+"/data/{data}/seed={replicate}.csv"

def alg_shell(algorithm):
    if algorithm == "tabu":
        return "/usr/bin/time -f \"%e\" -o {output.time} " \  
            "Rscript scripts/run_tabu.R " \
            "--filename_data {input.data} " \
            "--output_dir {config[output_dir]} " \
            "--score {wildcards.score} " \
            "--iss {wildcards.iss} " \
            "--iss.mu {wildcards.issmu} " \
            "--l {wildcards.l} " \
            "--k {wildcards.k} " \
            "--prior {wildcards.prior} " \
            "--beta {wildcards.beta} " \
            "--filename {output.adjmat} " 
    elif algorithm == "blip":
        return  "/usr/bin/time -f \"%e\" -o {output.time} " \  
                "Rscript scripts/run_blip.R " \
                "--filename_data {input.data} " \
                "--output_dir {config[output_dir]} " \
                "--time {wildcards.max_time} " \
                "--scorer.method {wildcards.scorermethod} " \
                "--solver.method {wildcards.solvermethod} " \
                "--indeg {wildcards.indeg} " \  
                "--cores {wildcards.cores} " \
                "--allocated {wildcards.allocated} " \
                "--scorefunction {wildcards.scorefunction} " \
                "--alpha {wildcards.alpha} " \
                "--verbose {wildcards.verbose} " \
                "--filename {output.adjmat} " 
    elif algorithm == "itsearch":
        return "/usr/bin/time -f \"%e\" -o {output.time} " \  
                "Rscript scripts/run_iterative_search.R "\
                "--filename_data {input.data} "\
                "--filename {output.adjmat} " \
                "--output_dir {config[output_dir]} "\
                "--seed {wildcards.replicate} "\
                "--map {wildcards.MAP} "\
                "--scoretype {wildcards.scoretype} " \
                "--chi {wildcards.chi} " \
                "--edgepf {wildcards.edgepf} " \
                "--am {wildcards.am} " \
                "--aw {wildcards.aw} " \
                "--plus1it {wildcards.plus1it} " \
                "--posterior {wildcards.posterior} " \
                "--title itsearch"
    elif algorithm == "pcalg":
        return  "/usr/bin/time -f \"%e\" -o {output.time} " \  
                "Rscript scripts/run_pcalg.R " \
                "--filename_data {input.data} "\
                "--alpha {wildcards.alpha} "\
                "--output_dir {config[output_dir]} "\
                "--seed {wildcards.replicate} "\
                "--filename {output.adjmat} "
    elif algorithm == "mmhc":
        return  "/usr/bin/time -f \"%e\" -o {output.time} " \  
                "Rscript scripts/run_mmhc.R "\
                "--filename_data {input.data} "\
                "--alpha {wildcards.alpha} "\
                "--output_dir {config[output_dir]} "\
                "--seed {wildcards.replicate} "\
                "--filename {output.adjmat} "
    elif algorithm == "gobnilp":
        return "touch {output.adjmat}.gobnilp.set && " \   
                "echo 'gobnilp/outputfile/adjacencymatrix = \"{output.adjmat}.bn.mat\" ' > {output.adjmat}.gobnilp.set &&" \
                "echo 'gobnilp/outputfile/scoreandtime = \"{output.adjmat}.score_and_time.txt\" ' >> {output.adjmat}.gobnilp.set &&" \
                "echo 'gobnilp/scoring/palim = {wildcards.palim} ' >> {output.adjmat}.gobnilp.set && " \     
                "echo 'gobnilp/scoring/alpha = {wildcards.alpha} ' >> {output.adjmat}.gobnilp.set && " \
                "echo 'gobnilp/scoring/prune = {wildcards.prune} ' >> {output.adjmat}.gobnilp.set && " \     
                "/myappdir/gobnilp163/bin/gobnilp -f=dat -g={output.adjmat}.gobnilp.set {input.data} " \
                " && cat {output.adjmat}.bn.mat > {output.adjmat} " \
                " && cat {output.adjmat}.score_and_time.txt > {output.time} " \ 
                " && rm {output.adjmat}.bn.mat " \
                " && rm {output.adjmat}.score_and_time.txt " \
                " && rm {output.adjmat}.gobnilp.set"
    elif algorithm ==  "fges":
        return "/usr/bin/time -f \"%e\" -o {output.time} " \  
                "java -jar causal-cmd-1.1.3-jar-with-dependencies.jar " \
                "--algorithm fges "\
                "--data-type {wildcards.datatype} "\
                "--dataset {input.data} "\
                "--delimiter space " \
                "--score {wildcards.score} "\
                "--json-graph "\
                "--structurePrior 1 "\
                "--prefix {output.adjmat} " \
                '&& Rscript scripts/tetrad_graph_to_adjmat.R ' \
                '--jsongraph {output.adjmat}_graph.json ' \
                '--filename {output.adjmat} ' \
                '&& ' \
                'rm {output.adjmat}_graph.json ' \
                '&& ' \
                'rm {output.adjmat}.txt'
    elif algorithm == "order_mcmc":
        return "/usr/bin/time -f \"%e\" -o {output.time} " \  
                "Rscript scripts/run_order_mcmc.R " \
                "--filename {output.adjvecs} " \
                "--filename_data {input.data} " \
                "--filename_startspace {input.startspace} " \   
                "--scoretype {wildcards.scoretype} " \
                "--chi {wildcards.chi} " \
                "--edgepf {wildcards.edgepf} " \
                "--aw {wildcards.aw} " \
                "--am {wildcards.am} " \
                "--output_dir {config[output_dir]} " \
                "--seed {wildcards.replicate} "
    elif algorithm == "trilearn_loglin":
        return "cp {input} {input}.tmp.csv " \
                "&& sed --in-place 's/\ /,/g' {input.data}.tmp.csv " \
                "&& pgibbs_loglinear_sample -N {wildcards.N} -M {wildcards.M} -f {input.data}.tmp.csv -o . -F {output.adjvecs} " \
                "&& rm {input.data}.tmp.csv " \
                "&& echo '1' > {output.time} "

def docker_image(algorithm):
    if algorithm == "trilearn_loglin":
        return "docker://onceltuca/trilearn:1.1"
    elif algorithm == "gobnilp":
        return "docker://onceltuca/gobnilp:1.6.3"

def summarise_alg_input_data_path():
    return config["output_dir"]+"/data/adjmat=/{adjmat}/bn=/{bn}/data=/{data}/seed={replicate}.csv"

def summarise_alg_input_adjmat_true_path():
    return config["output_dir"]+"/adjmat/{adjmat}.csv"

def summarise_alg_input_adjmat_est_path(algorithm):
    return config["output_dir"]+"/adjmat_estimate/"\
            "adjmat=/{adjmat}/"\
            "bn=/{bn}/"\
            "data=/{data}/"\
            "algorithm=/" + pattern_strings[algorithm] + "/" + \
            "seed={replicate}/" \
            "adjmat.csv",

def summarise_alg_input_time_path(algorithm):
    return config["output_dir"]+"/time/"\
                    "adjmat=/{adjmat}/"\
                    "bn=/{bn}/"\
                    "data=/{data}/" \ 
                    "algorithm=/" + pattern_strings[algorithm] + "/" + \
                    "seed={replicate}/" \
                    "time.txt"

def summarise_alg_output_res_path(algorithm):
    return config["output_dir"]+"/result/"\
            "algorithm=/" + pattern_strings[algorithm] + "/" + \
            "adjmat=/{adjmat}/"\
            "bn=/{bn}/"\
            "data=/{data}/"\
            "seed={replicate}/" \
            "legend={plot_legend}/" \        
            "result.csv"

def summarise_alg_shell(algorithm):
    if algorithm == "tabu":
        return  "Rscript scripts/run_summarise.R " \
                "--adjmat_true {input.adjmat_true} " \
                "--adjmat_est {input.adjmat_est} " \
                "--filename_data {input.data} " \
                "--range_header_data 1 " \ 
                "--filename {output.res} " \ 
                "--bdecatpar_chi {wildcards.bdecatpar_chi} " \
                "--bdecatpar_edgepf {wildcards.bdecatpar_edgepf} " \
                " && python scripts/add_column.py --filename {output} --colname replicate       --colval {wildcards.replicate} " \
                " && python scripts/add_column.py --filename {output} --colname algorithm       --colval tabu " \
                " && python scripts/add_column.py --filename {output} --colname adjmat          --colval {wildcards.adjmat} "  \       
                " && python scripts/add_column.py --filename {output} --colname bn              --colval {wildcards.bn} "  \       
                " && python scripts/add_column.py --filename {output} --colname data            --colval {wildcards.data} "  \       
                " && python scripts/add_column.py --filename {output} --colname score           --colval {wildcards.score} " \
                " && python scripts/add_column.py --filename {output} --colname iss             --colval {wildcards.iss} " \
                " && python scripts/add_column.py --filename {output} --colname iss.mu          --colval {wildcards.issmu} " \
                " && python scripts/add_column.py --filename {output} --colname l               --colval {wildcards.l} " \
                " && python scripts/add_column.py --filename {output} --colname k               --colval {wildcards.k} " \
                " && python scripts/add_column.py --filename {output} --colname prior           --colval {wildcards.prior} " \
                " && python scripts/add_column.py --filename {output} --colname beta            --colval {wildcards.beta} " \
                " && python scripts/add_column.py --filename {output} --colname bdecatpar_chi   --colval {wildcards.bdecatpar_chi} " \
                " && python scripts/add_column.py --filename {output} --colname bdecatpar_edgepf --colval {wildcards.bdecatpar_edgepf} " \
                " && python scripts/add_column.py --filename {output} --colname start           --colval null " \
                " && python scripts/add_column.py --filename {output} --colname whitelist       --colval null " \
                " && python scripts/add_column.py --filename {output} --colname blacklist       --colval null " \
                " && python scripts/add_column.py --filename {output} --colname debug           --colval false " \ 
                " && python scripts/add_column.py --filename {output} --colname tabu            --colval 10 " \
                " && python scripts/add_column.py --filename {output} --colname max.tabu        --colval tabu " \
                " && python scripts/add_column.py --filename {output} --colname max.iter        --colval Inf " \
                " && python scripts/add_column.py --filename {output} --colname maxp            --colval Inf " \
                " && python scripts/add_column.py --filename {output} --colname optimized       --colval true " \
                " && python scripts/add_column.py --filename {output} --colname time            --colval `cat {input.time}` " \
                " && python scripts/add_column.py --filename {output} --colname legend          --colval {wildcards.plot_legend} " 
    elif algorithm == "blip":
        return         "Rscript scripts/run_summarise.R " \
        "--adjmat_true {input.adjmat_true} " \
        "--adjmat_est {input.adjmat_est} " \
        "--filename_data {input.data} " \
        "--range_header_data 1 " \ 
        "--filename {output.res} " \ 
        "--bdecatpar_chi {wildcards.bdecatpar_chi} " \
        "--bdecatpar_edgepf {wildcards.bdecatpar_edgepf} " \
        " && python scripts/add_column.py --filename {output} --colname replicate       --colval {wildcards.replicate} " \
        " && python scripts/add_column.py --filename {output} --colname algorithm       --colval blip " \
        " && python scripts/add_column.py --filename {output} --colname adjmat          --colval {wildcards.adjmat} "  \       
        " && python scripts/add_column.py --filename {output} --colname bn              --colval {wildcards.bn} "  \       
        " && python scripts/add_column.py --filename {output} --colname data            --colval {wildcards.data} "  \       
        " && python scripts/add_column.py --filename {output} --colname score           --colval bde " \
        " && python scripts/add_column.py --filename {output} --colname bdecatpar_chi   --colval {wildcards.bdecatpar_chi} " \
        " && python scripts/add_column.py --filename {output} --colname bdecatpar_edgepf --colval {wildcards.bdecatpar_edgepf} " \
        " && python scripts/add_column.py --filename {output} --colname max_time        --colval {wildcards.max_time} " \
        " && python scripts/add_column.py --filename {output} --colname scorer.method   --colval {wildcards.scorermethod} " \
        " && python scripts/add_column.py --filename {output} --colname solver.method   --colval {wildcards.solvermethod} " \
        " && python scripts/add_column.py --filename {output} --colname indeg           --colval {wildcards.indeg} " \ 
        " && python scripts/add_column.py --filename {output} --colname cores           --colval {wildcards.cores} " \
        " && python scripts/add_column.py --filename {output} --colname allocated       --colval {wildcards.allocated} " \
        " && python scripts/add_column.py --filename {output} --colname scorefunction   --colval {wildcards.scorefunction} " \
        " && python scripts/add_column.py --filename {output} --colname alpha           --colval {wildcards.alpha} " \
        " && python scripts/add_column.py --filename {output} --colname verbose         --colval {wildcards.verbose} " \
        " && python scripts/add_column.py --filename {output} --colname time            --colval `cat {input.time}` " \
        " && python scripts/add_column.py --filename {output} --colname legend          --colval {wildcards.plot_legend} " 
    elif algorithm == "itsearch":
        return "Rscript scripts/run_summarise.R " \
        "--adjmat_true {input.adjmat_true} " \
        "--adjmat_est {input.adjmat_est} " \
        "--filename_data {input.data} " \
        "--filename {output} " \ 
        "--range_header_data 1 " \ 
        "--bdecatpar_chi {wildcards.chi} " \
        "--bdecatpar_edgepf {wildcards.edgepf} " \
        " && python scripts/add_column.py --filename {output} --colname replicate     --colval {wildcards.replicate} "\
        " && python scripts/add_column.py --filename {output} --colname algorithm     --colval itsearch "\
        " && python scripts/add_column.py --filename {output} --colname adjmat          --colval {wildcards.adjmat} "  \       
        " && python scripts/add_column.py --filename {output} --colname bn              --colval {wildcards.bn} "  \       
        " && python scripts/add_column.py --filename {output} --colname data            --colval {wildcards.data} "  \
        " && python scripts/add_column.py --filename {output} --colname plus1it       --colval {wildcards.plus1it} " \
        " && python scripts/add_column.py --filename {output} --colname moveprobs     --colval null " \
        " && python scripts/add_column.py --filename {output} --colname MAP           --colval {wildcards.MAP} " \            
        " && python scripts/add_column.py --filename {output} --colname posterior     --colval {wildcards.posterior} " \
        " && python scripts/add_column.py --filename {output} --colname iterations    --colval null " \
        " && python scripts/add_column.py --filename {output} --colname stepsave      --colval null " \
        " && python scripts/add_column.py --filename {output} --colname softlimit     --colval 9 " \ 
        " && python scripts/add_column.py --filename {output} --colname hardlimit     --colval 12 " \ 
        " && python scripts/add_column.py --filename {output} --colname alpha         --colval 0.05 " \ 
        " && python scripts/add_column.py --filename {output} --colname gamma         --colval 1  " \ 
        " && python scripts/add_column.py --filename {output} --colname startspace    --colval null " \ 
        " && python scripts/add_column.py --filename {output} --colname blacklist     --colval null " \ 
        " && python scripts/add_column.py --filename {output} --colname verbose       --colval true " \
        " && python scripts/add_column.py --filename {output} --colname chainout      --colval true " \
        " && python scripts/add_column.py --filename {output} --colname scoreout      --colval true " \
        " && python scripts/add_column.py --filename {output} --colname cpdag         --colval false " \
        " && python scripts/add_column.py --filename {output} --colname mergetype     --colval skeleton " \
        " && python scripts/add_column.py --filename {output} --colname addspace      --colval null " \
        " && python scripts/add_column.py --filename {output} --colname scoretable    --colval null " \
        " && python scripts/add_column.py --filename {output} --colname startorder    --colval null " \
        " && python scripts/add_column.py --filename {output} --colname accum         --colval false " \
        " && python scripts/add_column.py --filename {output} --colname scoretype    --colval {wildcards.scoretype} " \
        " && python scripts/add_column.py --filename {output} --colname chi          --colval {wildcards.chi} " \
        " && python scripts/add_column.py --filename {output} --colname edgepf       --colval {wildcards.edgepf} " \
        " && python scripts/add_column.py --filename {output} --colname am           --colval {wildcards.am} " \
        " && python scripts/add_column.py --filename {output} --colname aw           --colval {wildcards.aw} " \
        " && python scripts/add_column.py --filename {output} --colname time         --colval `cat {input.time}` "  \
        " && python scripts/add_column.py --filename {output} --colname legend        --colval {wildcards.plot_legend} "  
    elif algorithm == "pcalg":
        return "Rscript scripts/run_summarise.R " \
        "--adjmat_true {input.adjmat_true} " \
        "--adjmat_est {input.adjmat_est} " \
        "--filename_data {input.data} " \
        "--filename {output} " \ 
        "--range_header_data 1 " \ 
        "--bdecatpar_chi {wildcards.bdecatpar_chi} " \
        "--bdecatpar_edgepf {wildcards.bdecatpar_edgepf} " \
        " && python scripts/add_column.py --filename {output} --colname replicate   --colval {wildcards.replicate} "\
        " && python scripts/add_column.py --filename {output} --colname algorithm   --colval pcalg "\
        " && python scripts/add_column.py --filename {output} --colname adjmat          --colval {wildcards.adjmat} "  \       
        " && python scripts/add_column.py --filename {output} --colname bn              --colval {wildcards.bn} "  \       
        " && python scripts/add_column.py --filename {output} --colname data            --colval {wildcards.data} "  \       
        " && python scripts/add_column.py --filename {output} --colname alpha       --colval {wildcards.alpha} "\
        " && python scripts/add_column.py --filename {output} --colname score           --colval bde " \
        " && python scripts/add_column.py --filename {output} --colname bdecatpar_chi   --colval {wildcards.bdecatpar_chi} " \
        " && python scripts/add_column.py --filename {output} --colname bdecatpar_edgepf --colval {wildcards.bdecatpar_edgepf} " \    
        " && python scripts/add_column.py --filename {output} --colname fixedGaps   --colval null " \
        " && python scripts/add_column.py --filename {output} --colname fixedEdges  --colval null " \
        " && python scripts/add_column.py --filename {output} --colname NAdelete    --colval true " \
        " && python scripts/add_column.py --filename {output} --colname m.max       --colval inf " \
        " && python scripts/add_column.py --filename {output} --colname conservative --colval false " \
        " && python scripts/add_column.py --filename {output} --colname maj.rule     --colval false " \
        " && python scripts/add_column.py --filename {output} --colname solve.confl  --colval false " \
        " && python scripts/add_column.py --filename {output} --colname numCores     --colval 1 " \
        " && python scripts/add_column.py --filename {output} --colname verbose      --colval false " \
        " && python scripts/add_column.py --filename {output} --colname time          --colval `cat {input.time}` "  \
        " && python scripts/add_column.py --filename {output} --colname legend      --colval {wildcards.plot_legend} " 
    elif algorithm == "mmhc":
        return  "Rscript scripts/run_summarise.R " \
                "--adjmat_true {input.adjmat_true} " \
                "--adjmat_est {input.adjmat_est} " \
                "--filename_data {input.data} " \
                "--filename {output} " \ 
                "--range_header_data 1 " \ 
                "--bdecatpar_chi {wildcards.bdecatpar_chi} " \
                "--bdecatpar_edgepf {wildcards.bdecatpar_edgepf} " \
                " && python scripts/add_column.py --filename {output} --colname replicate   --colval {wildcards.replicate} "\
                " && python scripts/add_column.py --filename {output} --colname algorithm   --colval mmhc "\
                " && python scripts/add_column.py --filename {output} --colname adjmat          --colval {wildcards.adjmat} "  \       
                " && python scripts/add_column.py --filename {output} --colname bn              --colval {wildcards.bn} "  \       
                " && python scripts/add_column.py --filename {output} --colname data            --colval {wildcards.data} "  \       
                " && python scripts/add_column.py --filename {output} --colname score           --colval bde " \
                " && python scripts/add_column.py --filename {output} --colname bdecatpar_chi   --colval {wildcards.bdecatpar_chi} " \
                " && python scripts/add_column.py --filename {output} --colname bdecatpar_edgepf --colval {wildcards.bdecatpar_edgepf} " \
                " && python scripts/add_column.py --filename {output} --colname alpha       --colval {wildcards.alpha} " \
                " && python scripts/add_column.py --filename {output} --colname whitelist   --colval null " \
                " && python scripts/add_column.py --filename {output} --colname debug       --colval false " \
                " && python scripts/add_column.py --filename {output} --colname maximize.args   --colval null " \
                " && python scripts/add_column.py --filename {output} --colname time          --colval `cat {input.time}` " \
                " && python scripts/add_column.py --filename {output} --colname legend      --colval {wildcards.plot_legend} "  
    elif algorithm == "fges":
        return  "Rscript scripts/run_summarise.R " \
                "--adjmat_true {input.adjmat_true} " \
                "--adjmat_est {input.adjmat_est} " \
                "--filename_data {input.data} " \
                "--filename {output.res} " \ 
                "--range_header_data 1 " \ 
                "--bdecatpar_chi {wildcards.bdecatpar_chi} " \
                "--bdecatpar_edgepf {wildcards.bdecatpar_edgepf} " \        
                " && python scripts/add_column.py --filename {output} --colname replicate   --colval {wildcards.replicate} "\
                " && python scripts/add_column.py --filename {output} --colname algorithm   --colval fges "\
                " && python scripts/add_column.py --filename {output} --colname score           --colval bde " \
                " && python scripts/add_column.py --filename {output} --colname adjmat           --colval {wildcards.adjmat} " \
                " && python scripts/add_column.py --filename {output} --colname bn              --colval {wildcards.bn} " \
                " && python scripts/add_column.py --filename {output} --colname data           --colval {wildcards.data} " \
                " && python scripts/add_column.py --filename {output} --colname score           --colval bde " \
                " && python scripts/add_column.py --filename {output} --colname bdecatpar_chi   --colval {wildcards.bdecatpar_chi} " \
                " && python scripts/add_column.py --filename {output} --colname bdecatpar_edgepf --colval {wildcards.bdecatpar_edgepf} " \
                " && python scripts/add_column.py --filename {output} --colname faithfulnessAssumed       --colval {wildcards.faithfulnessAssumed} "\
                " && python scripts/add_column.py --filename {output} --colname time        --colval `cat {input.time}` " \
                " && python scripts/add_column.py --filename {output} --colname legend      --colval {wildcards.plot_legend} "  
    elif algorithm=="gobnilp":
        return  "Rscript scripts/run_summarise.R " \
                "--adjmat_true {input.adjmat_true} " \
                "--adjmat_est {input.adjmat_est} " \
                "--filename_data {input.data} " \
                "--filename {output.res} " \ 
                "--range_header_data 1 " \ 
                "--adjmat_header 0 " \ 
                "--bdecatpar_chi {wildcards.bdecatpar_chi} " \
                "--bdecatpar_edgepf {wildcards.bdecatpar_edgepf} " \
                " && python scripts/add_column.py --filename {output} --colname replicate   --colval {wildcards.replicate} "\
                " && python scripts/add_column.py --filename {output} --colname algorithm   --colval gobnilp "\
                " && python scripts/add_column.py --filename {output} --colname adjmat          --colval {wildcards.adjmat} "  \       
                " && python scripts/add_column.py --filename {output} --colname bn              --colval {wildcards.bn} "  \       
                " && python scripts/add_column.py --filename {output} --colname data            --colval {wildcards.data} "  \
                " && python scripts/add_column.py --filename {output} --colname score           --colval bde " \
                " && python scripts/add_column.py --filename {output} --colname bdecatpar_chi   --colval {wildcards.bdecatpar_chi} " \
                " && python scripts/add_column.py --filename {output} --colname bdecatpar_edgepf --colval {wildcards.bdecatpar_edgepf} " \
                " && python scripts/add_column.py --filename {output} --colname palim       --colval {wildcards.palim} "\
                " && python scripts/add_column.py --filename {output} --colname alpha       --colval {wildcards.alpha} "\
                " && python scripts/add_column.py --filename {output} --colname prune       --colval {wildcards.prune} "\
                " && python scripts/add_column.py --filename {output} --colname time        --colval `cat {input.time} | grep -Eo '[0-9]\.[0-9]*$'` " \
                " && python scripts/add_column.py --filename {output} --colname legend      --colval {wildcards.plot_legend} "  
    elif algorithm == "trilearn_loglin":
        return "Rscript scripts/run_summarise.R " \
                "--adjmat_true {input.adjmat_true} " \
                "--adjmat_est {input.adjmat_est} " \
                "--filename_data {input.data} " \
                "--range_header_data 1 " \ 
                "--filename {output} " \ 
                "--bdecatpar_chi {wildcards.bdecatpar_chi} " \
                "--bdecatpar_edgepf {wildcards.bdecatpar_edgepf} " \
                " && python scripts/add_column.py --filename {output} --colname replicate   --colval {wildcards.replicate} "\
                " && python scripts/add_column.py --filename {output} --colname algorithm   --colval trilearn_loglin "\
                " && python scripts/add_column.py --filename {output} --colname adjmat      --colval {wildcards.adjmat} "  \       
                " && python scripts/add_column.py --filename {output} --colname bn          --colval {wildcards.bn} "  \       
                " && python scripts/add_column.py --filename {output} --colname data        --colval {wildcards.data} "  \
                " && python scripts/add_column.py --filename {output} --colname alpha       --colval {wildcards.alpha} "\
                " && python scripts/add_column.py --filename {output} --colname beta        --colval {wildcards.beta} "\
                " && python scripts/add_column.py --filename {output} --colname radii       --colval {wildcards.radii} "\
                " && python scripts/add_column.py --filename {output} --colname N           --colval {wildcards.N} "\
                " && python scripts/add_column.py --filename {output} --colname M           --colval {wildcards.M} "\
                " && python scripts/add_column.py --filename {output} --colname pseudo_obs  --colval {wildcards.pseudo_obs} "\
                " && python scripts/add_column.py --filename {output} --colname alpha       --colval {wildcards.alpha} "\
                " && python scripts/add_column.py --filename {output} --colname threshold   --colval {wildcards.threshold} "\
                " && python scripts/add_column.py --filename {output} --colname time        --colval `cat {input.time}` " \ 
                " && python scripts/add_column.py --filename {output} --colname legend      --colval {wildcards.plot_legend} "  
    elif algorithm == "order_mcmc":
        return  "Rscript scripts/run_summarise.R " \
                "--adjmat_true {input.adjmat_true} " \
                "--adjmat_est {input.adjmat_est} " \
                "--filename_data {input.data} " \
                "--range_header_data 1 " \ 
                "--filename {output} " \ 
                "--bdecatpar_chi {wildcards.chi} " \
                "--bdecatpar_edgepf {wildcards.edgepf} " \
                " && python scripts/add_column.py --filename {output} --colname replicate   --colval {wildcards.replicate} "\
                " && python scripts/add_column.py --filename {output} --colname algorithm   --colval orderMCMC "\
                " && python scripts/add_column.py --filename {output} --colname adjmat          --colval {wildcards.adjmat} "  \       
                " && python scripts/add_column.py --filename {output} --colname bn              --colval {wildcards.bn} "  \       
                " && python scripts/add_column.py --filename {output} --colname data            --colval {wildcards.data} "  \
                " && python scripts/add_column.py --filename {output} --colname scoretype    --colval {wildcards.scoretype} " \
                " && python scripts/add_column.py --filename {output} --colname chi          --colval {wildcards.chi} " \
                " && python scripts/add_column.py --filename {output} --colname edgepf       --colval {wildcards.edgepf} " \
                " && python scripts/add_column.py --filename {output} --colname am           --colval {wildcards.am} " \
                " && python scripts/add_column.py --filename {output} --colname aw           --colval {wildcards.aw} " \
                " && python scripts/add_column.py --filename {output} --colname map         --colval null "\
                " && python scripts/add_column.py --filename {output} --colname blacklist   --colval null "\
                " && python scripts/add_column.py --filename {output} --colname startorder  --colval null "\
                " && python scripts/add_column.py --filename {output} --colname scoretable  --colval null "\
                " && python scripts/add_column.py --filename {output} --colname moveprobs   --colval null "\
                " && python scripts/add_column.py --filename {output} --colname iterations  --colval null "\
                " && python scripts/add_column.py --filename {output} --colname stepwise    --colval null "\
                " && python scripts/add_column.py --filename {output} --colname alpha       --colval 0.05 "\
                " && python scripts/add_column.py --filename {output} --colname cpdag       --colval false "\   
                " && python scripts/add_column.py --filename {output} --colname gamma       --colval 1 "\
                " && python scripts/add_column.py --filename {output} --colname hardlimit   --colval 15 "\      
                " && python scripts/add_column.py --filename {output} --colname chainout    --colval true "\   
                " && python scripts/add_column.py --filename {output} --colname scoreout    --colval false "\   
                " && python scripts/add_column.py --filename {output} --colname verbose     --colval false "\
                " && python scripts/add_column.py --filename {output} --colname threshold   --colval {wildcards.threshold} "\
                " && python scripts/add_column.py --filename {output} --colname startspace   --colval {wildcards.startspace_algorithm} "\
                " && python scripts/add_column.py --filename {output} --colname time        --colval `cat {input.time}` " \ 
                " && python scripts/add_column.py --filename {output} --colname legend      --colval {wildcards.plot_legend} "  

configfile: 
    "config.json"

replicates = range(int(config["data"]["replicates"]["start"]), 
                    int(config["data"]["replicates"]["end"]+1))

# TODO: All filenames should be generated from the config file.

singularity:
    "docker://onceltuca/benchmark:1.0.7"

rule heatmap_from_adjmat_trajectory:
    input:
        adjvecs = config["output_dir"]+"/adjvecs/{something}/seed={seed}/adjvecs.json"
    output:
        heatmap = config["output_dir"]+"/heatmap_estimate/{something}/burnin={burnin}/seed={seed}/heatmap.csv" 
    message:
        "Estimating heatmap from graph trajectory"
    shell:
        "Rscript scripts/run_estimate_heatmap_from_traj.R " \
        "--adjvectraj {input.adjvecs} " \
        "--filename {output.heatmap} " \
        "--tosymmetric 0"

rule size_autocorrelation_from_trajectory:
   input:
       adjvecs = config["output_dir"]+"/adjvecs/{something}/adjvecs.json" 
   output:
       autocorr = config["output_dir"]+"/autocorr_estimate/{something}/burnin={burnin}/autocorr.csv" 

rule adjmat_from_heatmap:
    input:
        heatmap=config["output_dir"]+"/heatmap_estimate/"\ 
                "{something}/"\
                "burnin={burnin}/"\
                "{somethingelse}/" \
                "heatmap.csv"
    output:
        adjmat_est=config["output_dir"]+"/adjmat_estimate/"\
                    "{something}/" + pattern_strings["mcmc_est"] + "/{somethingelse}/"\
                    "adjmat.csv"
    message:
        "Estimating adjmat from heatmap"
    shell:
        "Rscript scripts/run_threshold_heatmap.R " \
        "--heatmap {input.heatmap} " \
        "--filename {output.adjmat_est} " \
        "--threshold {wildcards.threshold}"

rule bnlearn_adjmat:
    input:
        config["output_dir"] + "/bn/bn.fit_networks/{name}.rds"
    output:
        config["output_dir"] + "/adjmat/bn.fit_adjmats/{name}.csv"
    shell:
        "mkdir -p {config[output_dir]}" + "/adjmat/bn.fit_adjmats/ " \
        "&& Rscript scripts/bnlearn_bn_to_adjmat.R " 
        "--filename_graph {output} "
        "--filename_bn {input}"

rule bnlearn_networks:
    output:
        config["output_dir"] + "/bn/bn.fit_networks/{bn}.rds"
    shell:
        "mkdir -p {config[output_dir]}" + "/bn/bn.fit_networks/ " \
        "&& wget https://www.bnlearn.com/bnrepository/{wildcards.bn}/{wildcards.bn}.rds "
        "--output-document {output}"

rule sample_adjmat:
    output:        
        adjmat = config["output_dir"] + "/adjmat/generateDAGMaxParents/p={p}/avpar={avparents}/seed={replicate}.csv"
    shell:
        "Rscript scripts/sample_dags.R " \
        "--filename {output.adjmat} " \ 
        "--nodes {wildcards.p} " \
        "--parents {wildcards.avparents} " \
        "--seed {wildcards.replicate}"

rule sample_binary_bn:
    input:
        adjmat = "{output_dir}/adjmat/{adjmat}.csv" 
    output:
        bn = "{output_dir}/bn/generateBinaryBN/min={min}/max={max}/seed={seed}/adjmat=/{adjmat}.rds"
    shell:
        "Rscript scripts/sample_bayesian_network_for_dag.R " \
        "--filename_dag {input.adjmat} " \
        "--filename {output} "  \
        "--seed {wildcards.seed} "

rule sample_bindata:
    input:
        bn="{output_dir}/bn/generateBinaryBN/{bn}/adjmat=/{adjmat}.rds"
    output:
        data="{output_dir}/data/adjmat=/{adjmat}/bn=/generateBinaryBN/{bn}/data=/n={n}/seed={replicate}.csv"
    shell:
        "Rscript scripts/sample_data_with_range_header.R " \
        "--filename {output.data} " \
        "--filename_bn {input.bn} " \
        "--samples {wildcards.n} " \
        "--seed {wildcards.replicate}"

rule copy_fixed_data:
    input:
        "{output_dir}/data/mydatasets/{filename}.csv" # this ensures that the file exists and is copied again if changed.
    output:
        data="{output_dir}/data/adjmat=/{adjmat}/bn=/None/data=/generation_method=fixed/name={filename}/n={n}/seed={replicate}.csv"
    shell:\
        "mkdir -p {wildcards.output_dir}/data/adjmat=/{wildcards.adjmat}/bn=/None/data=/generation_method=fixed/name={wildcards.filename}/n={wildcards.n} && "\
        "cp {input} {output.data}"

rule sample_bnfit_data:
    input:        
        bn="{output_dir}/bn/bn.fit_networks/{bn}.rds"        
    output:
        data="{output_dir}/data/adjmat=/{adjmat}/bn=/bn.fit_networks/{bn}/data=/n={n}/seed={replicate}.csv"
    shell:
        "Rscript scripts/sample_from_bnlearn_bn.R " \
        "--filename {output.data} " \
        "--filename_bn {input.bn} " \
        "--samples {wildcards.n} " \
        "--seed {wildcards.replicate}"

rule sample_data_range_header:
    input:
        bn="{output_dir}/bn/generateBinaryBN/{bn}/adjmat=/{adjmat}.rds"
    output:                
        data="{output_dir}/data/adjmat=/{adjmat}/bn=/generateBinaryBN/{bn}/range_header_data=/n={n}/seed={replicate}.csv"
    shell:
        "Rscript scripts/sample_data_with_range_header.R " \
        "--filename {output.data} "\                
        "--filename_bn {input.bn} " \
        "--samples {wildcards.n} " \
        "--seed {wildcards.replicate}"

rule tabu:
    input:
        data = alg_input_data()
    output:
        adjmat = alg_output_adjmat_path("tabu"),
        time = alg_output_time_path("tabu")
    message:
        "Executing tabu algorithm on the following files: {input}."
    shell:
        alg_shell("tabu")

rule summarise_tabu:
    input:
        data = summarise_alg_input_data_path(),
        adjmat_true = summarise_alg_input_adjmat_true_path(),
        adjmat_est = summarise_alg_input_adjmat_est_path("tabu"),
        time = summarise_alg_input_time_path("tabu")
    output:
        res = summarise_alg_output_res_path("tabu")
    message:
        "Summarising tabu results based on the files: {input}."
    shell:
        summarise_alg_shell("tabu")
       
rule join_summaries_tabu:
    input:
        conf="config.json",
        res=join_string_sampled_model("tabu"),
        fixed_res = join_string_fixed_data("tabu")
    output:
        join_summaries_output("tabu")
    shell:
        join_summaries_shell("tabu")

rule blip:
    input:
        data = alg_input_data()
    output:
        adjmat = alg_output_adjmat_path("blip"),
        time = alg_output_time_path("blip")
    message:
        "Executing blip algorithm on the following files: {input}."
    shell:        
        alg_shell("blip")

rule summarise_blip:
    input:
        data = summarise_alg_input_data_path(),
        adjmat_true = summarise_alg_input_adjmat_true_path(),
        adjmat_est = summarise_alg_input_adjmat_est_path("blip"),
        time = summarise_alg_input_time_path("blip")
    output:
        res = summarise_alg_output_res_path("blip")
    message:
        "Summarising blip results based on the files: {input}."
    shell:
        summarise_alg_shell("blip")

rule join_summaries_blip:
    input:
        conf="config.json",
        res=join_string_sampled_model("blip"),
        fixed_res = join_string_fixed_data("blip")
    output:
        join_summaries_output("blip")
    shell:
        join_summaries_shell("blip")

rule itsearch:
    input:
        data = alg_input_data()
    output:
        adjmat = alg_output_adjmat_path("itsearch"),
        time = alg_output_time_path("itsearch")
    message:
        "Executing iterative search algorithm with wildcards {wildcards} on the following data: {input}"
    shell:
        alg_shell("itsearch")

rule summarise_itsearch:
    input:
        data = summarise_alg_input_data_path(),
        adjmat_true = summarise_alg_input_adjmat_true_path(),
        adjmat_est = summarise_alg_input_adjmat_est_path("itsearch"),
        time = summarise_alg_input_time_path("itsearch")
    output:
        res = summarise_alg_output_res_path("itsearch")
    message:
        "Summarising iterative search algorithm with wildcards: {wildcards} on the following files: {input}"
    shell:
        summarise_alg_shell("itsearch")

rule join_summaries_itsearch:
    input:
        conf="config.json",
        res=join_string_sampled_model("itsearch"),
        fixed_res = join_string_fixed_data("itsearch")
    output:
        join_summaries_output("itsearch")
    shell:
        join_summaries_shell("itsearch")

rule pcalg:
    input:
        data = alg_input_data()
    output:
        adjmat = alg_output_adjmat_path("pcalg"),
        time = alg_output_time_path("pcalg")
    message:
        "Executing order PC algorithm on the following files: {input}."
    shell:
       alg_shell("pcalg")

rule summarise_pcalg:
    input:
        data = summarise_alg_input_data_path(),
        adjmat_true = summarise_alg_input_adjmat_true_path(),
        adjmat_est = summarise_alg_input_adjmat_est_path("pcalg"),
        time = summarise_alg_input_time_path("pcalg")
    output:
        res = summarise_alg_output_res_path("pcalg")
    message:
        "Summarising pc algorithm based on the following files: {input}."
    shell:
        summarise_alg_shell("pcalg")

rule join_summaries_pcalg:
    input:
        conf="config.json",
        res=join_string_sampled_model("pcalg"),
        fixed_res = join_string_fixed_data("pcalg")
    output:
        join_summaries_output("pcalg")
    shell:
        join_summaries_shell("pcalg")

rule mmhc:
    input:
        data = alg_input_data()
    output:
        adjmat = alg_output_adjmat_path("mmhc"),
        time = alg_output_time_path("mmhc")
    message:
        "Executing the mmhc algorithm on the following files: {input}."
    shell:
        alg_shell("mmhc")

rule summarise_mmhc:
    input:
        data = summarise_alg_input_data_path(),
        adjmat_true = summarise_alg_input_adjmat_true_path(),
        adjmat_est = summarise_alg_input_adjmat_est_path("mmhc"),
        time = summarise_alg_input_time_path("mmhc")
    output:
        res = summarise_alg_output_res_path("mmhc")
    shell:
       summarise_alg_shell("mmhc")

rule join_summaries_mmhc:
    input:
        conf="config.json",
        res=join_string_sampled_model("mmhc"),
        fixed_res = join_string_fixed_data("mmhc")
    output:
        join_summaries_output("mmhc")  
    shell:
        join_summaries_shell("mmhc")

rule gobnilp:
    input:
        data = alg_input_data()
    output:
        adjmat = alg_output_adjmat_path("gobnilp"),
        time = alg_output_time_path("gobnilp")
    singularity:
        docker_image("gobnilp")        
    shell: 
        alg_shell("gobnilp")

rule summarise_gobnilp:
    input:
        data = summarise_alg_input_data_path(),
        adjmat_true = summarise_alg_input_adjmat_true_path(),
        adjmat_est = summarise_alg_input_adjmat_est_path("gobnilp"),
        time = summarise_alg_input_time_path("gobnilp")
    output:
        res = summarise_alg_output_res_path("gobnilp")
    shell:
        summarise_alg_shell("gobnilp")

rule join_summaries_gobnilp:
    input:
        conf="config.json",
        res=join_string_sampled_model("gobnilp"),
        fixed_res = join_string_fixed_data("gobnilp")     
    output:
        join_summaries_output("gobnilp")
    shell:
        join_summaries_shell("gobnilp")
rule fges:
    input:
        data = alg_input_data()
    output:
        adjmat = alg_output_adjmat_path("fges"),
        time = alg_output_time_path("fges")
    message:
        "Executing fges algorithm on the following files: {input}."
    shell:
        alg_shell("fges")

rule summarise_fges:
    input:
        data = summarise_alg_input_data_path(),
        adjmat_true = summarise_alg_input_adjmat_true_path(),
        adjmat_est = summarise_alg_input_adjmat_est_path("fges"),
        time = summarise_alg_input_time_path("fges")
    output:
        res = summarise_alg_output_res_path("fges")
    message:
        "Summarising fges results based on the files: {input}."
    shell:
        summarise_alg_shell("fges")

rule join_summaries_fges:
    input: # This could be a funciton since no pattern mathing is going on here
        conf="config.json",
        res=join_string_sampled_model("fges"),
        fixed_res = join_string_fixed_data("fges") 
    output:
        join_summaries_output("fges")
    shell:
        join_summaries_shell("fges")

rule order_mcmc:
    input:
        data = alg_input_data(),
        startspace = config["output_dir"]+"/adjmat_estimate/{data}/algorithm=/{startspace_algorithm}/seed={replicate}/adjmat.csv"
    output:
        adjvecs = alg_output_adjvecs_path("order_mcmc"),
        time = alg_output_time_path("order_mcmc")
    message:
        "Executing order mcmc algorithm with startspace on the following files: {input}.\n Output: {output}"
    shell: 
       alg_shell("order_mcmc")

rule summarise_order_mcmc:
    input:
        data = data_path(),
        adjmat_true = adjmat_true_path(),
        adjmat_est = adjmat_estimate_path_mcmc("order_mcmc"),
        time = time_path("order_mcmc")
    output:
        res = result_path_mcmc("order_mcmc")
    message:
        "Summarizing order mcmc algorithm with startspace on the following files: {input}."
    shell: 
        summarise_alg_shell("order_mcmc")

rule join_summaries_order_mcmc:
    input: 
        conf="config.json",
        res=join_string_sampled_model_mcmc("order_mcmc"),
        fixed_res = join_string_fixed_data_mcmc("order_mcmc")
    output:
        join_summaries_output("order_mcmc")
    shell:
        join_summaries_shell("order_mcmc")

rule trilearn_loglin:
    input:
        data=alg_input_data()
    output:
        adjvecs = alg_output_adjvecs_path("trilearn_loglin"),
        time = alg_output_time_path("trilearn_loglin")
    message:
        "Executing trilearn algorithm on the following files: {input}, output: {output}. wildcards {wildcards}"
    singularity:
        docker_image("trilearn_loglin")
    shell:
        alg_shell("trilearn_loglin")

rule summarise_trilearn_loglin:
    input:
        data = data_path(),
        adjmat_true = adjmat_true_path(),
        adjmat_est = adjmat_estimate_path_mcmc("trilearn_loglin"),
        time = time_path("trilearn_loglin")
    output:
        res = result_path_mcmc("trilearn_loglin")
    message:
        "Summarizing trilearn algorithm with startspace on the following files: {input}, output: {output}."
    shell: 
        summarise_alg_shell("trilearn_loglin")

rule join_summaries_trilearn_loglin:
    input: 
        conf="config.json",
        res=join_string_sampled_model_mcmc("trilearn_loglin"),
        fixed_res = join_string_fixed_data_mcmc("trilearn_loglin")
    output:
        join_summaries_output("trilearn_loglin")
    message:
        "Input: {input}"
    shell:
        join_summaries_shell("trilearn_loglin")

rule roc:
    input:
        "config.json",
        "Snakefile",
        active_algorithm_files
    output:
        config["output_dir"] + "/ROC.eps", \
        config["output_dir"] + "/ROC_data.csv" 
    shell:
        "Rscript scripts/combine_ROC_data.R "\
        "&& Rscript scripts/plot_ROC.R"