import json

pattern_strings = {}
pattern_strings["blip"] =   "blip/alg_params=/" \
                "score_type={score_type}/" \
                "bdecatpar_chi={bdecatpar_chi}/" \
                "bdecatpar_edgepf={bdecatpar_edgepf}/" \
                "time={max_time}/" \
                "scorer.method={scorermethod}/" \
                "solver.method={solvermethod}/" \
                "indeg={indeg}/" \        
                "cores={cores}/" \
                "allocated={allocated}/" \
                "scorefunction={scorefunction}/" \
                "alpha={alpha}/" \
                "verbose={verbose}"

pattern_strings["pcalg"] = "pcalg/alg_params=/"\
               "score_type={score_type}/" \
               "bdecatpar_chi={bdecatpar_chi}/" \
               "bdecatpar_edgepf={bdecatpar_edgepf}/" \
               "alpha={alpha}"

pattern_strings["mmhc"] = "mmhc/alg_params=/"\
               "score_type={score_type}/" \
               "bdecatpar_chi={bdecatpar_chi}/" \
               "bdecatpar_edgepf={bdecatpar_edgepf}/" \
               "alpha={alpha}"

pattern_strings["tabu"] = "tabu/alg_params=/"\
               "score_type={score_type}/" \
               "bdecatpar_chi={bdecatpar_chi}/" \
               "bdecatpar_edgepf={bdecatpar_edgepf}/" \
               "score={score}/"\
               "iss={iss}/"\
               "iss.mu={issmu}/"\
               "l={l}/"\
               "k={k}/"\
               "prior={prior}/"\
               "beta={beta}"\

pattern_strings["gobnilp"] = "gobnilp/alg_params=/"\
                 "score_type={score_type}/" \
                 "bdecatpar_chi={bdecatpar_chi}/" \
                 "bdecatpar_edgepf={bdecatpar_edgepf}/" \
                 "palim={palim}" \
                 "alpha={alpha}"\
                 "prune={prune}"

pattern_strings["fges"] = "fges/alg_params=/"\
               "score_type={score_type}/" \
               "bdecatpar_chi={bdecatpar_chi}/" \
               "bdecatpar_edgepf={bdecatpar_edgepf}/" \
               "score={score}/" \
               "data-type={datatype}/"\
               "faithfulnessAssumed={faithfulnessAssumed}"

pattern_strings["itsearch"] =   "itsearch/alg_params=/"\
                    "scoretype={scoretype}/"\
                    "chi={chi}/" \
                    "edgepf={edgepf}/" \
                    "am={am}/" \
                    "aw={aw}/" \
                    "map={MAP}/"\
                    "plus1it={plus1it}/"\
                    "posterior={posterior}"

pattern_strings["order_mcmc"] = "order_mcmc/alg_params=/"\
                    "scoretype={scoretype}/"\
                    "chi={chi}/" \
                    "edgepf={edgepf}/" \
                    "am={am}/" \
                    "aw={aw}/" \
                    "startspace_algorithm=/{startspace_algorithm}"

pattern_strings["mcmc_est"] = "estimation_method/"\
                  "threshold={threshold}/"\
                  "burnin={burnin}"

pattern_strings["trilearn_loglin"] = "trilearn_loglin/alg_params=/"\
                  "score_type={score_type}/"\
                  "bdecatpar_chi={bdecatpar_chi}/" \
                  "bdecatpar_edgepf={bdecatpar_edgepf}/" \
                  "alpha={alpha}/"\
                  "beta={beta}/"\
                  "radii={radii}/"\
                  "pseudo_obs={pseudo_obs}/"\
                  "N={N}/"\
                  "M={M}"

pattern_strings["evaluation"] = "evaluation/" \
                   "score_type={score_type}/" \
                   "bdecatpar_chi={bdecatpar_chi}/" \
                   "bdecatpar_edgepf={bdecatpar_edgepf}" 

with open('config.json') as json_file:
    conf = json.load(json_file)

# This is to be used for startspace for certain methods.
# Method with severalvalues for one arguments will be added here as well even though these 
# never used. E.g. pcalg have typically several alphas.
# TODO: Could it also be expanded to use in the join functions?
json_string = {}
json_string = {key: expand(pattern_strings["itsearch"], 
                                            scoretype=val["optional"]["scoretype"],
                                            chi=val["optional"]["chi"],
                                           edgepf=val["optional"]["edgepf"],
                                           am=val["optional"]["am"],
                                           aw=val["optional"]["aw"],
                                           MAP=val["optional"]["MAP"],
                                           plus1it=val["optional"]["plus1it"],
                                           posterior=val["optional"]["posterior"]) 
                    for key,val in conf["algorithms"]["itsearch"].items()}

json_string.update({key: expand(pattern_strings["fges"], score_type="bdecat",
                                           bdecatpar_chi=conf["evaluation"]["score"]["bdecatpar"]["chi"],
                                           bdecatpar_edgepf=conf["evaluation"]["score"]["bdecatpar"]["edgepf"],
                                           faithfulnessAssumed=val["faithfulnessAssumed"],
                                           datatype=val["data-type"],
                                           score=val["score"]) 
                    for key,val in conf["algorithms"]["fges"].items()})

json_string.update({key: expand(pattern_strings["pcalg"], score_type="bdecat",
                                           bdecatpar_chi=conf["evaluation"]["score"]["bdecatpar"]["chi"],
                                           bdecatpar_edgepf=conf["evaluation"]["score"]["bdecatpar"]["edgepf"],
                                           alpha=val["alpha"])  
                    for key, val in conf["algorithms"]["pcalg"].items() } )

json_string.update({key: expand(pattern_strings["mmhc"], score_type="bdecat",
                                           bdecatpar_chi=conf["evaluation"]["score"]["bdecatpar"]["chi"],
                                           bdecatpar_edgepf=conf["evaluation"]["score"]["bdecatpar"]["edgepf"],
                                           alpha=val["restrict.args"]["alpha"])  
                    for key, val in conf["algorithms"]["mmhc"].items() } )

json_string.update({key: expand(pattern_strings["gobnilp"], score_type="bdecat",
                                                bdecatpar_chi=conf["evaluation"]["score"]["bdecatpar"]["chi"],
                                                bdecatpar_edgepf=conf["evaluation"]["score"]["bdecatpar"]["edgepf"],
                                                palim=val["palim"],
                                                alpha=val["alpha"],
                                                prune=val["prune"]
                                                )
                for key, val in conf["algorithms"]["gobnilp"].items()})

json_string.update({key:  expand(pattern_strings["tabu"], score_type="bdecat",
                                                    bdecatpar_chi=conf["evaluation"]["score"]["bdecatpar"]["chi"],
                                                    bdecatpar_edgepf=conf["evaluation"]["score"]["bdecatpar"]["edgepf"],
                                                    score=val["score"],
                                                    iss=val["iss"],
                                                    issmu=val["iss.mu"],
                                                    l=val["l"],
                                                    k=val["k"],
                                                    prior=val["prior"],
                                                    beta=val["beta"],
                                                    )
                for key, val in conf["algorithms"]["tabu"].items()})

json_string.update({key: expand(pattern_strings["trilearn_loglin"], score_type="bdecat",
                                                    bdecatpar_chi=conf["evaluation"]["score"]["bdecatpar"]["chi"],
                                                    bdecatpar_edgepf=conf["evaluation"]["score"]["bdecatpar"]["edgepf"],
                                                    alpha=val["alpha"],
                                                    beta=val["beta"],
                                                    N=val["N"],
                                                    M=val["M"],
                                                    pseudo_obs=val["pseudo_obs"],
                                                    radii=val["radii"])
                for key, val in conf["algorithms"]["trilearn_loglin"].items()})

json_string.update({key: expand(pattern_strings["blip"], score_type="bdecat",
                                            bdecatpar_chi=conf["evaluation"]["score"]["bdecatpar"]["chi"],
                                            bdecatpar_edgepf=conf["evaluation"]["score"]["bdecatpar"]["edgepf"],
                                            max_time=val["time"],
                                            solvermethod=val["solver.method"],
                                            scorermethod=val["scorer.method"],
                                            indeg=val["indeg"],
                                            cores=val["cores"],
                                            allocated=val["allocated"],
                                            scorefunction=val["scorefunction"],
                                            alpha=val["alpha"],
                                            verbose=val["verbose"]
                                            )
                for key, val in conf["algorithms"]["blip"].items()})

# This has to be the last one since it takes input strings as start space...
json_string.update({key: expand(pattern_strings["order_mcmc"], 
                                            scoretype="bdecat",
                                            chi=val["chi"],
                                            edgepf=val["edgepf"],
                                            am=val["am"],
                                            aw=val["aw"],
                                            startspace_algorithm=json_string[val["startspace"]])  
                    for key, val in conf["algorithms"]["order_mcmc"].items() } )

def gen_model_strings_from_conf(models, seed, setup):
    """
    Generate the graphs and paremeters simulatnepusly since we do not want 
    every combiantion of graphs and paramters.
    Maybe this should be part of the setup? -No, this part belongs to the method step, 
    not the model/data simulation step.
    There are 3 steps.
    1. Specify the models.
    2. Generate data sets from the models.
    3. Run a nunmber of structure learningn algortithms on th dataset.
    """
    pass

def gen_adjmat_string_from_conf(adjmat_gen_method, seed, setup):
    with open('config.json') as json_file:
        conf = json.load(json_file)

    fixed_graphs = ["asia", "survey", "alarm", "sachs", "hepar2", "hailfinder"]
    if adjmat_gen_method == "generateDAGMaxParents":
        curconf = conf["graphs"]["sampled"]["algorithms"][adjmat_gen_method]
        n_simulation_setups = len(conf["data"]["sample_sizes"])
        return expand(adjmat_gen_method + \
            "/p={p}" + 
            "/avpar={av_parents}" + 
            "/seed={seed}",
            av_parents=curconf["av_parents"][setup], 
            p=curconf["dims"][setup],
            seed=seed) 
    elif adjmat_gen_method in fixed_graphs:
        return "bn.fit_adjmats/" + adjmat_gen_method    

def gen_parameter_string_from_conf(gen_method, seed):
    with open('config.json') as json_file:
        conf = json.load(json_file)

    if gen_method == "generateBinaryBN":
        curconf = conf["model_parameters"]["sampled"]["algorithms"][gen_method]
        return expand(gen_method + \
                "/min={min}" + \
                "/max={max}" + \
                "/seed={seed}", 
                min=curconf["min"], 
                max=curconf["max"], 
                seed=seed)
    elif gen_method in ["asia", "survey", "hailfinder", "alarm", "sachs", "hepar2"]:
        return "bn.fit_networks/"+gen_method

def active_algorithm_files(wildcards):
    with open('config.json') as json_file:
        conf = json.load(json_file)
    algs = []
    for alg, val in conf["algorithms"].items():     
        for alg_conf in conf["plotting"]["algorithms"]:
            if alg_conf in val:
                    algs.append(conf["output_dir"] + "/" + alg + ".csv")
    return algs

configfile: 
    "config.json"

replicates = range(int(config["data"]["replicates"]["start"]), 
                    int(config["data"]["replicates"]["end"]+1))

# TODO: All filenames should be generated from the config file.

singularity:
    "docker://onceltuca/benchmark:1.0.7"

rule bnlearn_adjmat:
    input:
        config["output_dir"] + "/bn/bn.fit_networks/{name}.rds"
    output:
        config["output_dir"] + "/adjmat/bn.fit_adjmats/{name}.csv"
    shell:
        "mkdir -p {config[output_dir]}" + "/adjmat/bn.fit_adjmats/ " \
        "&& Rscript scripts/bnlearn_bn_to_adjmat.R " 
        "--filename_graph {output} "
        "--filename_bn {input}"

rule bnlearn_networks:
    output:
        config["output_dir"] + "/bn/bn.fit_networks/{bn}.rds"
    shell:
        "mkdir -p {config[output_dir]}" + "/bn/bn.fit_networks/ " \
        "&& wget https://www.bnlearn.com/bnrepository/{wildcards.bn}/{wildcards.bn}.rds "
        "--output-document {output}"

rule sample_adjmat:
    output:        
        adjmat = config["output_dir"] + "/adjmat/generateDAGMaxParents/p={p}/avpar={avparents}/seed={replicate}.csv"
    shell:
        "Rscript scripts/sample_dags.R " \
        "--filename {output.adjmat} " \ 
        "--nodes {wildcards.p} " \
        "--parents {wildcards.avparents} " \
        "--seed {wildcards.replicate}"

rule sample_binary_bn:
    input:
        adjmat = "{output_dir}/adjmat/{adjmat}.csv" 
    output:
        bn = "{output_dir}/bn/generateBinaryBN/min={min}/max={max}/seed={seed}/adjmat=/{adjmat}.rds"
    shell:
        "Rscript scripts/sample_bayesian_network_for_dag.R " \
        "--filename_dag {input.adjmat} " \
        "--filename {output} "  \
        "--seed {wildcards.seed} "

rule sample_bindata:
    input:
        bn="{output_dir}/bn/generateBinaryBN/{bn}/adjmat=/{adjmat}.rds"
    output:
        data="{output_dir}/data/adjmat=/{adjmat}/bn=/generateBinaryBN/{bn}/data=/n={n}/seed={replicate}.csv"
    shell:
        "Rscript scripts/sample_data_with_range_header.R " \
        "--filename {output.data} " \
        "--filename_bn {input.bn} " \
        "--samples {wildcards.n} " \
        "--seed {wildcards.replicate}"

rule copy_fixed_data:
    input:
        "{output_dir}/data/mydatasets/{filename}.csv" # this ensures that the file exists and is copied again if changed.
    output:
        data="{output_dir}/data/adjmat=/{adjmat}/bn=/None/data=/generation_method=fixed/name={filename}/n={n}/seed={replicate}.csv"
    shell:\
        "mkdir -p {wildcards.output_dir}/data/adjmat=/{wildcards.adjmat}/bn=/None/data=/generation_method=fixed/name={wildcards.filename}/n={wildcards.n} && "\
        "cp {input} {output.data}"

rule sample_bnfit_data:
    input:        
        bn="{output_dir}/bn/bn.fit_networks/{bn}.rds"        
    output:
        data="{output_dir}/data/adjmat=/{adjmat}/bn=/bn.fit_networks/{bn}/data=/n={n}/seed={replicate}.csv"
    shell:
        "Rscript scripts/sample_from_bnlearn_bn.R " \
        "--filename {output.data} " \
        "--filename_bn {input.bn} " \
        "--samples {wildcards.n} " \
        "--seed {wildcards.replicate}"

rule sample_data_range_header:
    input:
        bn="{output_dir}/bn/generateBinaryBN/{bn}/adjmat=/{adjmat}.rds"
    output:                
        data="{output_dir}/data/adjmat=/{adjmat}/bn=/generateBinaryBN/{bn}/range_header_data=/n={n}/seed={replicate}.csv"
    shell:
        "Rscript scripts/sample_data_with_range_header.R " \
        "--filename {output.data} "\                
        "--filename_bn {input.bn} " \
        "--samples {wildcards.n} " \
        "--seed {wildcards.replicate}"

rule tabu:
    input:
        data = config["output_dir"]+"/data/{data}/seed={replicate}.csv"
    output:
        adjmat = config["output_dir"]+"/adjmat_estimate/{data}/"\
                "algorithm=/" + pattern_strings["tabu"] + "/" +\
                "seed={replicate}/" \
                "adjmat.csv",
        time = config["output_dir"] + "/time/{data}/"\
                "algorithm=/" + pattern_strings["tabu"] + "/" +\
                "seed={replicate}/" \
                "time.txt"

    message:
        "Executing blip algorithm on the following files: {input}."
    shell:
        "/usr/bin/time -f \"%e\" -o {output.time} " \  
        "Rscript scripts/run_tabu.R " \
        "--filename_data {input.data} " \
        "--output_dir {config[output_dir]} " \
        "--score {wildcards.score} " \
        "--iss {wildcards.iss} " \
        "--iss.mu {wildcards.issmu} " \
        "--l {wildcards.l} " \
        "--k {wildcards.k} " \
        "--prior {wildcards.prior} " \
        "--beta {wildcards.beta} " \
        "--filename {output.adjmat} " 

rule trilearn_loglin:
    input:
        config["output_dir"]+"/data/{graph_param_data}/seed={replicate}.csv"
    output:
        adjvecs = config["output_dir"]+"/adjvecs/{graph_param_data}/"\
                "algorithm=/"  + pattern_strings["trilearn_loglin"] + "/" + \
                "seed={replicate}/" \
                "adjvecs.json",
        time = config["output_dir"] + "/time/{graph_param_data}/"\
                "algorithm=/" + pattern_strings["trilearn_loglin"] + "/" + \
                "seed={replicate}/" \
                "time.txt"
    message:
        "Executing trilearn algorithm on the following files: {input}."
    singularity:
        "docker://onceltuca/trilearn:1.1"
    shell:
        "cp {input} {input}.tmp.csv " \
        "&& sed --in-place 's/\ /,/g' {input}.tmp.csv " \
        "&& pgibbs_loglinear_sample -N {wildcards.N} -M {wildcards.M} -f {input}.tmp.csv -o . -F {output.adjvecs} " \
        "&& rm {input}.tmp.csv "
        "&& echo '1' > {output.time} "

rule summarise_trilearn_loglin:
    input:
        data = config["output_dir"]+"/data/adjmat=/{adjmat}/bn=/{bn}/data=/{data}/seed={replicate}.csv", 
        adjmat_true = config["output_dir"]+"/adjmat/{adjmat}.csv",
        adjmat_est =  config["output_dir"]+"/adjmat_estimate/"\
                        "adjmat=/{adjmat}/"\
                        "bn=/{bn}/"\
                        "data=/{data}/"\
                        "algorithm=/" + pattern_strings["trilearn_loglin"] +"/"+  pattern_strings["mcmc_est"] + "/" \
                        "seed={replicate}/" \
                        "adjmat.csv",
        time = config["output_dir"]+"/time/"\
                    "adjmat=/{adjmat}/"\
                    "bn=/{bn}/"\
                    "data=/{data}/"\
                    "algorithm=/" + pattern_strings["trilearn_loglin"] +  "/" \
                    "seed={replicate}/" \
                    "time.txt",
    output:
        res = config["output_dir"]+"/result/"\
            "algorithm=/" + pattern_strings["trilearn_loglin"] + "/"+ pattern_strings["mcmc_est"] + "/"\
            "adjmat=/{adjmat}/"\
            "bn=/{bn}/"\
            "data=/{data}/"\   
            "seed={replicate}/" \
            "legend={plot_legend}/" \        
            "result.csv",
    message:
        "Summarizing trilearn algorithm with startspace on the following files: {input}."
    shell: 
        "Rscript scripts/run_summarise.R " \
        "--adjmat_true {input.adjmat_true} " \
        "--adjmat_est {input.adjmat_est} " \
        "--filename_data {input.data} " \
        "--range_header_data 1 " \ 
        "--filename {output} " \ 
        "--bdecatpar_chi {wildcards.bdecatpar_chi} " \
        "--bdecatpar_edgepf {wildcards.bdecatpar_edgepf} " \
        " && python scripts/add_column.py --filename {output} --colname replicate   --colval {wildcards.replicate} "\
        " && python scripts/add_column.py --filename {output} --colname algorithm   --colval trilearn_loglin "\
        " && python scripts/add_column.py --filename {output} --colname adjmat      --colval {wildcards.adjmat} "  \       
        " && python scripts/add_column.py --filename {output} --colname bn          --colval {wildcards.bn} "  \       
        " && python scripts/add_column.py --filename {output} --colname data        --colval {wildcards.data} "  \
        " && python scripts/add_column.py --filename {output} --colname alpha       --colval {wildcards.alpha} "\
        " && python scripts/add_column.py --filename {output} --colname beta        --colval {wildcards.beta} "\
        " && python scripts/add_column.py --filename {output} --colname radii       --colval {wildcards.radii} "\
        " && python scripts/add_column.py --filename {output} --colname N           --colval {wildcards.N} "\
        " && python scripts/add_column.py --filename {output} --colname M           --colval {wildcards.M} "\
        " && python scripts/add_column.py --filename {output} --colname pseudo_obs  --colval {wildcards.pseudo_obs} "\
        " && python scripts/add_column.py --filename {output} --colname alpha       --colval {wildcards.alpha} "\
        " && python scripts/add_column.py --filename {output} --colname threshold   --colval {wildcards.threshold} "\
        " && python scripts/add_column.py --filename {output} --colname time        --colval `cat {input.time}` " \ 
        " && python scripts/add_column.py --filename {output} --colname legend      --colval {wildcards.plot_legend} "  

rule summarise_tabu:
    input:
        data = config["output_dir"]+"/data/adjmat=/{adjmat}/bn=/{bn}/data=/{data}/seed={replicate}.csv", 
        adjmat_true = config["output_dir"]+"/adjmat/{adjmat}.csv",
        adjmat_est =  config["output_dir"]+"/adjmat_estimate/"\
                        "adjmat=/{adjmat}/"\
                        "bn=/{bn}/"\
                        "data=/{data}/"\
                        "algorithm=/" + pattern_strings["tabu"] + "/" +
                        "seed={replicate}/" \
                        "adjmat.csv",
        time = config["output_dir"]+"/time/"\
                    "adjmat=/{adjmat}/"\
                    "bn=/{bn}/"\
                    "data=/{data}/" \ 
                    "algorithm=/" + pattern_strings["tabu"] + "/" +
                    "seed={replicate}/" \
                    "time.txt",
    output:
        res = config["output_dir"]+"/result/"\
            "algorithm=/" + pattern_strings["tabu"] + "/" +
            "adjmat=/{adjmat}/"\
            "bn=/{bn}/"\
            "data=/{data}/"\
            "seed={replicate}/" \
            "legend={plot_legend}/" \        
            "result.csv",
    message:
        "Summarising tabu results based on the files: {input}."
    shell:
        "Rscript scripts/run_summarise.R " \
        "--adjmat_true {input.adjmat_true} " \
        "--adjmat_est {input.adjmat_est} " \
        "--filename_data {input.data} " \
        "--range_header_data 1 " \ 
        "--filename {output.res} " \ 
        "--bdecatpar_chi {wildcards.bdecatpar_chi} " \
        "--bdecatpar_edgepf {wildcards.bdecatpar_edgepf} " \
        " && python scripts/add_column.py --filename {output} --colname replicate       --colval {wildcards.replicate} " \
        " && python scripts/add_column.py --filename {output} --colname algorithm       --colval tabu " \
        " && python scripts/add_column.py --filename {output} --colname adjmat          --colval {wildcards.adjmat} "  \       
        " && python scripts/add_column.py --filename {output} --colname bn              --colval {wildcards.bn} "  \       
        " && python scripts/add_column.py --filename {output} --colname data            --colval {wildcards.data} "  \       
        " && python scripts/add_column.py --filename {output} --colname score           --colval {wildcards.score} " \
        " && python scripts/add_column.py --filename {output} --colname iss             --colval {wildcards.iss} " \
        " && python scripts/add_column.py --filename {output} --colname iss.mu          --colval {wildcards.issmu} " \
        " && python scripts/add_column.py --filename {output} --colname l               --colval {wildcards.l} " \
        " && python scripts/add_column.py --filename {output} --colname k               --colval {wildcards.k} " \
        " && python scripts/add_column.py --filename {output} --colname prior           --colval {wildcards.prior} " \
        " && python scripts/add_column.py --filename {output} --colname beta            --colval {wildcards.beta} " \
        " && python scripts/add_column.py --filename {output} --colname bdecatpar_chi   --colval {wildcards.bdecatpar_chi} " \
        " && python scripts/add_column.py --filename {output} --colname bdecatpar_edgepf --colval {wildcards.bdecatpar_edgepf} " \
        " && python scripts/add_column.py --filename {output} --colname start           --colval null " \
        " && python scripts/add_column.py --filename {output} --colname whitelist       --colval null " \
        " && python scripts/add_column.py --filename {output} --colname blacklist       --colval null " \
        " && python scripts/add_column.py --filename {output} --colname debug           --colval false " \ 
        " && python scripts/add_column.py --filename {output} --colname tabu            --colval 10 " \
        " && python scripts/add_column.py --filename {output} --colname max.tabu        --colval tabu " \
        " && python scripts/add_column.py --filename {output} --colname max.iter        --colval Inf " \
        " && python scripts/add_column.py --filename {output} --colname maxp            --colval Inf " \
        " && python scripts/add_column.py --filename {output} --colname optimized       --colval true " \
        " && python scripts/add_column.py --filename {output} --colname time            --colval `cat {input.time}` " \
        " && python scripts/add_column.py --filename {output} --colname legend          --colval {wildcards.plot_legend} " 

# def shell_command(alg):
#     #return alg
#     if alg == "blip":
#         return "/usr/bin/time -f \"%e\" -o {output.time} " 
#         command = "/usr/bin/time -f \"%e\" -o {output.time} " \  
#             "Rscript scripts/run_blip.R " \
#             "--filename_data {input.data} " \
#             "--output_dir {config[output_dir]} " \
#             "--time {wildcards.max_time} " \
#             "--scorer.method {wildcards.scorermethod} " \
#             "--solver.method {wildcards.solvermethod} " \
#             "--indeg {wildcards.indeg} " \  
#             "--cores {wildcards.cores} " \
#             "--allocated {wildcards.allocated} " \
#             "--scorefunction {wildcards.scorefunction} " \
#             "--alpha {wildcards.alpha} " \
#             "--verbose {wildcards.verbose} " \
#             "--filename {output.adjmat} " 
#         return command

# rule run_algorithm:
#     input:
#         data = config["output_dir"]+"/data/{data}/seed={replicate}.csv"
#     output:
#         adjmat = config["output_dir"]+"/adjmat_estimate/{data}/" + \
#                  "algorithm=/{algorithm}/alg_parameters=/{alg_parameters}" + "/"\
#                 "seed={replicate}/" \
#                 "adjmat.csv",
#         time = config["output_dir"] + "/time/{data}/"\
#                 "algorithm=/{algorithm}/alg_parameters=/{alg_parameters}" + "/"\
#                 "seed={replicate}/" \
#                 "time.txt"
#     run:
#         if wildcards.algorithm == "blip":
#             command = "/usr/bin/time -f \"%e\" -o {output.time} " \  
#             "Rscript scripts/run_blip.R " \
#             "--filename_data {input.data} " \
#             "--output_dir {config[output_dir]} " \
#             "--time {wildcards.max_time} " \
#             "--scorer.method {wildcards.scorermethod} " \
#             "--solver.method {wildcards.solvermethod} " \
#             "--indeg {wildcards.indeg} " \  
#             "--cores {wildcards.cores} " \
#             "--allocated {wildcards.allocated} " \
#             "--scorefunction {wildcards.scorefunction} " \
#             "--alpha {wildcards.alpha} " \
#             "--verbose {wildcards.verbose} " \
#             "--filename {output.adjmat} " 
#             #shell("{wildcards.algorithm}")
#             shell(command)

# rule run_algorithm_pseudo:
#     input:
#         data = config["output_dir"]+"/data/{data}/seed={replicate}.csv"
#         adjmat = config["output_dir"]+"/adjmat_estimate/{data}/" + \
#                  "algorithm=/"+get_alg_pattern("{wildcards.alg_parameters}") + "/"\
#                 "seed={replicate}/" \
#                 "adjmat.csv",
#         time = config["output_dir"] + "/time/{data}/"\
#                 "algorithm=/"+get_alg_pattern("{wildcards.alg_parameters}") + "/"\
#                 "algorithm=/{algorithm}/alg_parameters=/{alg_parameters}" + "/"\
#                 "seed={replicate}/" \
#                 "time.txt"
#         # get input data string some way..
#         # this seems to be hard to automate since the pattern matching becomes hard
#         # maybe this canbe a wrapper 
#     output:
#         adjmat = config["output_dir"]+"/adjmat_estimate/{data}/" + \
#                  "algorithm=/{algorithm}/alg_parameters=/{alg_parameters}" + "/"\
#                 "seed={replicate}/" \
#                 "adjmat.csv",
#         time = config["output_dir"] + "/time/{data}/"\
#                 "algorithm=/{algorithm}/alg_parameters=/{alg_parameters}" + "/"\
#                 "seed={replicate}/" \
#                 "time.txt"

rule blip:
    input:
        data = config["output_dir"]+"/data/{data}/seed={replicate}.csv"
    output:
        adjmat = config["output_dir"]+"/adjmat_estimate/{data}/"\
                "algorithm=/" + pattern_strings["blip"] + "/"\
                "seed={replicate}/" \
                "adjmat.csv",
        time = config["output_dir"] + "/time/{data}/"\
                "algorithm=/" + pattern_strings["blip"] + "/"\
                "seed={replicate}/" \
                "time.txt"
    message:
            "Executing blip algorithm on the following files: {input}."
    shell:        
        "/usr/bin/time -f \"%e\" -o {output.time} " \  
        "Rscript scripts/run_blip.R " \
        "--filename_data {input.data} " \
        "--output_dir {config[output_dir]} " \
        "--time {wildcards.max_time} " \
        "--scorer.method {wildcards.scorermethod} " \
        "--solver.method {wildcards.solvermethod} " \
        "--indeg {wildcards.indeg} " \  
        "--cores {wildcards.cores} " \
        "--allocated {wildcards.allocated} " \
        "--scorefunction {wildcards.scorefunction} " \
        "--alpha {wildcards.alpha} " \
        "--verbose {wildcards.verbose} " \
        "--filename {output.adjmat} " 

rule summarise_blip:
    input:
        data = config["output_dir"]+"/data/adjmat=/{adjmat}/bn=/{bn}/data=/{data}/seed={replicate}.csv", 
        adjmat_true = config["output_dir"]+"/adjmat/{adjmat}.csv",
        adjmat_est =  config["output_dir"]+"/adjmat_estimate/"\
                        "adjmat=/{adjmat}/"\
                        "bn=/{bn}/"\
                        "data=/{data}/"\
                        "algorithm=/" + pattern_strings["blip"] + "/"\
                        "seed={replicate}/" \
                        "adjmat.csv",
        time = config["output_dir"]+"/time/"\
                    "adjmat=/{adjmat}/"\
                    "bn=/{bn}/"\
                    "data=/{data}/" \ 
                    "algorithm=/" + pattern_strings["blip"] + "/" \
                    "seed={replicate}/" \
                    "time.txt",
    output:
        res = config["output_dir"]+"/result/"\
            "algorithm=/" + pattern_strings["blip"] + "/" \
            "adjmat=/{adjmat}/"\
            "bn=/{bn}/"\
            "data=/{data}/"\
            "seed={replicate}/" \
            "legend={plot_legend}/" \        
            "result.csv",
    message:
        "Summarising blip results based on the files: {input}."
    shell:
        "Rscript scripts/run_summarise.R " \
        "--adjmat_true {input.adjmat_true} " \
        "--adjmat_est {input.adjmat_est} " \
        "--filename_data {input.data} " \
        "--range_header_data 1 " \ 
        "--filename {output.res} " \ 
        "--bdecatpar_chi {wildcards.bdecatpar_chi} " \
        "--bdecatpar_edgepf {wildcards.bdecatpar_edgepf} " \
        " && python scripts/add_column.py --filename {output} --colname replicate       --colval {wildcards.replicate} " \
        " && python scripts/add_column.py --filename {output} --colname algorithm       --colval blip " \
        " && python scripts/add_column.py --filename {output} --colname adjmat          --colval {wildcards.adjmat} "  \       
        " && python scripts/add_column.py --filename {output} --colname bn              --colval {wildcards.bn} "  \       
        " && python scripts/add_column.py --filename {output} --colname data            --colval {wildcards.data} "  \       
        " && python scripts/add_column.py --filename {output} --colname score           --colval bde " \
        " && python scripts/add_column.py --filename {output} --colname bdecatpar_chi   --colval {wildcards.bdecatpar_chi} " \
        " && python scripts/add_column.py --filename {output} --colname bdecatpar_edgepf --colval {wildcards.bdecatpar_edgepf} " \
        " && python scripts/add_column.py --filename {output} --colname max_time        --colval {wildcards.max_time} " \
        " && python scripts/add_column.py --filename {output} --colname scorer.method   --colval {wildcards.scorermethod} " \
        " && python scripts/add_column.py --filename {output} --colname solver.method   --colval {wildcards.solvermethod} " \
        " && python scripts/add_column.py --filename {output} --colname indeg           --colval {wildcards.indeg} " \ 
        " && python scripts/add_column.py --filename {output} --colname cores           --colval {wildcards.cores} " \
        " && python scripts/add_column.py --filename {output} --colname allocated       --colval {wildcards.allocated} " \
        " && python scripts/add_column.py --filename {output} --colname scorefunction   --colval {wildcards.scorefunction} " \
        " && python scripts/add_column.py --filename {output} --colname alpha           --colval {wildcards.alpha} " \
        " && python scripts/add_column.py --filename {output} --colname verbose         --colval {wildcards.verbose} " \
        " && python scripts/add_column.py --filename {output} --colname time            --colval `cat {input.time}` " \
        " && python scripts/add_column.py --filename {output} --colname legend          --colval {wildcards.plot_legend} " 
        
rule itsearch:
    input:
        data = config["output_dir"]+"/data/{data}/seed={replicate}.csv"
    output:
        adjmat = config["output_dir"]+"/adjmat_estimate/{data}/"\
                "algorithm=/" + pattern_strings["itsearch"] + "/" +\
                "seed={replicate}/" \
                "adjmat.csv",
        time = config["output_dir"] + "/time/{data}/"\
                "algorithm=/" + pattern_strings["itsearch"] + "/" +\
                "seed={replicate}/" \
                "time.txt"

    message:
        "Executing iterative search algorithm with MAP={wildcards.MAP} on the following data: {input}"
    shell:
        "/usr/bin/time -f \"%e\" -o {output.time} " \  
        "Rscript scripts/run_iterative_search.R "\
        "--filename_data {input.data} "\
        "--filename {output.adjmat} " \
        "--output_dir {config[output_dir]} "\
        "--seed {wildcards.replicate} "\
        "--map {wildcards.MAP} "\
        "--scoretype {wildcards.scoretype} " \
        "--chi {wildcards.chi} " \
        "--edgepf {wildcards.edgepf} " \
        "--am {wildcards.am} " \
        "--aw {wildcards.aw} " \
        "--plus1it {wildcards.plus1it} " \
        "--posterior {wildcards.posterior} " \
        "--title itsearch"\

rule summarise_itsearch:
    input:
        data = config["output_dir"]+"/data/adjmat=/{adjmat}/bn=/{bn}/data=/{data}/seed={replicate}.csv", 
        adjmat_true = config["output_dir"]+"/adjmat/{adjmat}.csv",
        adjmat_est =  config["output_dir"]+"/adjmat_estimate/"\
                        "adjmat=/{adjmat}/"\
                        "bn=/{bn}/"\
                        "data=/{data}/"\
                        "algorithm=/" + pattern_strings["itsearch"] + "/" + \
                        "seed={replicate}/" \
                        "adjmat.csv",
        time = config["output_dir"]+"/time/"\
                    "adjmat=/{adjmat}/"\
                    "bn=/{bn}/"\
                    "data=/{data}/" \ 
                    "algorithm=/" + pattern_strings["itsearch"] + "/" + \
                    "seed={replicate}/" \
                    "time.txt",
    output:
        res = config["output_dir"]+"/result/"\
            "algorithm=/" + pattern_strings["itsearch"] + "/" +
            "adjmat=/{adjmat}/"\
            "bn=/{bn}/"\
            "data=/{data}/"\
            "seed={replicate}/" \
            "legend={plot_legend}/" \        
            "result.csv",
    message:
        "Executing iterative search algorithm with MAP={wildcards.MAP} on the following files: {input}"
    shell:
        "Rscript scripts/run_summarise.R " \
        "--adjmat_true {input.adjmat_true} " \
        "--adjmat_est {input.adjmat_est} " \
        "--filename_data {input.data} " \
        "--filename {output} " \ 
        "--range_header_data 1 " \ 
        "--bdecatpar_chi {wildcards.chi} " \
        "--bdecatpar_edgepf {wildcards.edgepf} " \
        " && python scripts/add_column.py --filename {output} --colname replicate     --colval {wildcards.replicate} "\
        " && python scripts/add_column.py --filename {output} --colname algorithm     --colval itsearch "\
        " && python scripts/add_column.py --filename {output} --colname adjmat          --colval {wildcards.adjmat} "  \       
        " && python scripts/add_column.py --filename {output} --colname bn              --colval {wildcards.bn} "  \       
        " && python scripts/add_column.py --filename {output} --colname data            --colval {wildcards.data} "  \
        " && python scripts/add_column.py --filename {output} --colname plus1it       --colval {wildcards.plus1it} " \
        " && python scripts/add_column.py --filename {output} --colname moveprobs     --colval null " \
        " && python scripts/add_column.py --filename {output} --colname MAP           --colval {wildcards.MAP} " \            
        " && python scripts/add_column.py --filename {output} --colname posterior     --colval {wildcards.posterior} " \
        " && python scripts/add_column.py --filename {output} --colname iterations    --colval null " \
        " && python scripts/add_column.py --filename {output} --colname stepsave      --colval null " \
        " && python scripts/add_column.py --filename {output} --colname softlimit     --colval 9 " \ 
        " && python scripts/add_column.py --filename {output} --colname hardlimit     --colval 12 " \ 
        " && python scripts/add_column.py --filename {output} --colname alpha         --colval 0.05 " \ 
        " && python scripts/add_column.py --filename {output} --colname gamma         --colval 1  " \ 
        " && python scripts/add_column.py --filename {output} --colname startspace    --colval null " \ 
        " && python scripts/add_column.py --filename {output} --colname blacklist     --colval null " \ 
        " && python scripts/add_column.py --filename {output} --colname verbose       --colval true " \
        " && python scripts/add_column.py --filename {output} --colname chainout      --colval true " \
        " && python scripts/add_column.py --filename {output} --colname scoreout      --colval true " \
        " && python scripts/add_column.py --filename {output} --colname cpdag         --colval false " \
        " && python scripts/add_column.py --filename {output} --colname mergetype     --colval skeleton " \
        " && python scripts/add_column.py --filename {output} --colname addspace      --colval null " \
        " && python scripts/add_column.py --filename {output} --colname scoretable    --colval null " \
        " && python scripts/add_column.py --filename {output} --colname startorder    --colval null " \
        " && python scripts/add_column.py --filename {output} --colname accum         --colval false " \
        " && python scripts/add_column.py --filename {output} --colname scoretype    --colval {wildcards.scoretype} " \
        " && python scripts/add_column.py --filename {output} --colname chi          --colval {wildcards.chi} " \
        " && python scripts/add_column.py --filename {output} --colname edgepf       --colval {wildcards.edgepf} " \
        " && python scripts/add_column.py --filename {output} --colname am           --colval {wildcards.am} " \
        " && python scripts/add_column.py --filename {output} --colname aw           --colval {wildcards.aw} " \
        " && python scripts/add_column.py --filename {output} --colname time         --colval `cat {input.time}` "  \
        " && python scripts/add_column.py --filename {output} --colname legend        --colval {wildcards.plot_legend} "  

rule order_mcmc:
    input:
        data = config["output_dir"]+"/data/{graph_param_data}/seed={replicate}.csv",
        startspace = config["output_dir"]+"/adjmat_estimate/{graph_param_data}/algorithm=/{startspace_algorithm}/seed={replicate}/adjmat.csv"
    output:
        adjvecs = config["output_dir"]+"/adjvecs/{graph_param_data}/"\
                "algorithm=/"  + pattern_strings["order_mcmc"] + "/"  + \
                "seed={replicate}/" \
                "adjvecs.json",
        time = config["output_dir"] + "/time/{graph_param_data}/"\
                "algorithm=/" + pattern_strings["order_mcmc"] + "/" + \
                "seed={replicate}/" \
                "time.txt"
    message:
        "Executing order mcmc algorithm with startspace on the following files: {input}."
    shell: 
        "/usr/bin/time -f \"%e\" -o {output.time} " \  
        "Rscript scripts/run_order_mcmc.R "
        "--filename {output.adjvecs} " \
        "--filename_data {input.data} " \
        "--filename_startspace {input.startspace} " \   
        "--scoretype {wildcards.scoretype} " \
        "--chi {wildcards.chi} " \
        "--edgepf {wildcards.edgepf} " \
        "--aw {wildcards.aw} " \
        "--am {wildcards.am} " \
        "--output_dir {config[output_dir]} " \
        "--seed {wildcards.replicate} "

rule heatmap_from_adjmat_trajectory:
    input:
        adjvecs = config["output_dir"]+"/adjvecs/{something}/seed={seed}/adjvecs.json"
    output:
        heatmap = config["output_dir"]+"/heatmap_estimate/{something}/burnin={burnin}/seed={seed}/heatmap.csv" 
    message:
        "Estimating heatmap from graph trajectory"
    shell:
        "Rscript scripts/run_estimate_heatmap_from_traj.R " \
        "--adjvectraj {input.adjvecs} " \
        "--filename {output.heatmap} " \
        "--tosymmetric 0"

rule size_autocorrelation_from_trajectory:
   input:
       adjvecs = config["output_dir"]+"/adjvecs/{something}/adjvecs.json" 
   output:
       autocorr = config["output_dir"]+"/autocorr_estimate/{something}/burnin={burnin}/autocorr.csv" 


rule adjmat_from_heatmap:
    input:
        heatmap=config["output_dir"]+"/heatmap_estimate/"\ 
                "{something}/"\
                "burnin={burnin}/"\
                "{somethingelse}/" \
                "heatmap.csv"
    output:
        adjmat_est=config["output_dir"]+"/adjmat_estimate/"\
                    "{something}/" + pattern_strings["mcmc_est"] + "/{somethingelse}/"\
                    "adjmat.csv"
    message:
        "Estimating adjmat from heatmap"
    shell:
        "Rscript scripts/run_threshold_heatmap.R " \
        "--heatmap {input.heatmap} " \
        "--filename {output.adjmat_est} " \
        "--threshold {wildcards.threshold}"

rule summarise_ordermcmc:
    input:
        data = config["output_dir"]+"/data/adjmat=/{adjmat}/bn=/{bn}/data=/{data}/seed={replicate}.csv", 
        adjmat_true = config["output_dir"]+"/adjmat/{adjmat}.csv",
        adjmat_est =  config["output_dir"]+"/adjmat_estimate/"\
                        "adjmat=/{adjmat}/"\
                        "bn=/{bn}/"\
                        "data=/{data}/"\
                        "algorithm=/" + pattern_strings["order_mcmc"] + "/" + pattern_strings["mcmc_est"] + "/" \
                        "seed={replicate}/" \
                        "adjmat.csv",
        time = config["output_dir"]+"/time/"\
                    "adjmat=/{adjmat}/"\
                    "bn=/{bn}/"\
                    "data=/{data}/"\
                    "algorithm=/" + pattern_strings["order_mcmc"] + "/" + \
                    "seed={replicate}/" \
                    "time.txt",
    output:
        res = config["output_dir"]+"/result/"\
            "algorithm=/" + pattern_strings["order_mcmc"] + "/" + pattern_strings["mcmc_est"] + "/"\
            "adjmat=/{adjmat}/"\
            "bn=/{bn}/"\
            "data=/{data}/"\   
            "seed={replicate}/" \
            "legend={plot_legend}/" \        
            "result.csv",
    message:
        "Summarizing order mcmc algorithm with startspace on the following files: {input}."
    shell: 
        "Rscript scripts/run_summarise.R " \
        "--adjmat_true {input.adjmat_true} " \
        "--adjmat_est {input.adjmat_est} " \
        "--filename_data {input.data} " \
        "--range_header_data 1 " \ 
        "--filename {output} " \ 
        "--bdecatpar_chi {wildcards.chi} " \
        "--bdecatpar_edgepf {wildcards.edgepf} " \
        " && python scripts/add_column.py --filename {output} --colname replicate   --colval {wildcards.replicate} "\
        " && python scripts/add_column.py --filename {output} --colname algorithm   --colval orderMCMC "\
        " && python scripts/add_column.py --filename {output} --colname adjmat          --colval {wildcards.adjmat} "  \       
        " && python scripts/add_column.py --filename {output} --colname bn              --colval {wildcards.bn} "  \       
        " && python scripts/add_column.py --filename {output} --colname data            --colval {wildcards.data} "  \
        " && python scripts/add_column.py --filename {output} --colname scoretype    --colval {wildcards.scoretype} " \
        " && python scripts/add_column.py --filename {output} --colname chi          --colval {wildcards.chi} " \
        " && python scripts/add_column.py --filename {output} --colname edgepf       --colval {wildcards.edgepf} " \
        " && python scripts/add_column.py --filename {output} --colname am           --colval {wildcards.am} " \
        " && python scripts/add_column.py --filename {output} --colname aw           --colval {wildcards.aw} " \
        " && python scripts/add_column.py --filename {output} --colname map         --colval null "\
        " && python scripts/add_column.py --filename {output} --colname blacklist   --colval null "\
        " && python scripts/add_column.py --filename {output} --colname startorder  --colval null "\
        " && python scripts/add_column.py --filename {output} --colname scoretable  --colval null "\
        " && python scripts/add_column.py --filename {output} --colname moveprobs   --colval null "\
        " && python scripts/add_column.py --filename {output} --colname iterations  --colval null "\
        " && python scripts/add_column.py --filename {output} --colname stepwise    --colval null "\
        " && python scripts/add_column.py --filename {output} --colname alpha       --colval 0.05 "\
        " && python scripts/add_column.py --filename {output} --colname cpdag       --colval false "\   
        " && python scripts/add_column.py --filename {output} --colname gamma       --colval 1 "\
        " && python scripts/add_column.py --filename {output} --colname hardlimit   --colval 15 "\      
        " && python scripts/add_column.py --filename {output} --colname chainout    --colval true "\   
        " && python scripts/add_column.py --filename {output} --colname scoreout    --colval false "\   
        " && python scripts/add_column.py --filename {output} --colname verbose     --colval false "\
        " && python scripts/add_column.py --filename {output} --colname threshold   --colval {wildcards.threshold} "\
        " && python scripts/add_column.py --filename {output} --colname startspace   --colval {wildcards.startspace_algorithm} "\
        " && python scripts/add_column.py --filename {output} --colname time        --colval `cat {input.time}` " \ 
        " && python scripts/add_column.py --filename {output} --colname legend      --colval {wildcards.plot_legend} "  

rule pcalg:
    input:
        data = config["output_dir"]+"/data/{data}/seed={replicate}.csv"        
    output:
        adjmat = config["output_dir"]+"/adjmat_estimate/{data}/"\
                "algorithm=/" + pattern_strings["pcalg"] + "/" +\
                "seed={replicate}/" \
                "adjmat.csv",        
        time = config["output_dir"] + "/time/{data}/"\
                "algorithm=/" + pattern_strings["pcalg"] + "/" +\
                "seed={replicate}/" \
                "time.txt"
    message:
        "Executing order pc algorithm on the following files: {input}."
    shell:
        "/usr/bin/time -f \"%e\" -o {output.time} " \  
        "Rscript scripts/run_pcalg.R " \
        "--filename_data {input.data} "\
        "--alpha {wildcards.alpha} "\
        "--output_dir {config[output_dir]} "\
        "--seed {wildcards.replicate} "\
        "--filename {output.adjmat} "

rule summarise_pcalg:
    input:
        data = config["output_dir"]+"/data/adjmat=/{adjmat}/bn=/{bn}/data=/{data}/seed={replicate}.csv", 
        adjmat_true = config["output_dir"]+"/adjmat/{adjmat}.csv",
        adjmat_est =  config["output_dir"]+"/adjmat_estimate/"\
                        "adjmat=/{adjmat}/"\
                        "bn=/{bn}/"\
                        "data=/{data}/"\
                        "algorithm=/" + pattern_strings["pcalg"] + "/" +\
                        "seed={replicate}/" \
                        "adjmat.csv",
        time = config["output_dir"]+"/time/"\
                    "adjmat=/{adjmat}/"\
                    "bn=/{bn}/"\
                    "data=/{data}/" \ 
                    "algorithm=/" + pattern_strings["pcalg"] + "/" +\
                    "seed={replicate}/" \
                    "time.txt",
    output:
        res = config["output_dir"]+"/result/"\
            "algorithm=/" + pattern_strings["pcalg"] + "/" + \
            "adjmat=/{adjmat}/"\
            "bn=/{bn}/"\
            "data=/{data}/"\
            "seed={replicate}/" \
            "legend={plot_legend}/" \        
            "result.csv",
    message:
        "Summarising pc algorithm based on the following files: {input}."
    shell:
        "Rscript scripts/run_summarise.R " \
        "--adjmat_true {input.adjmat_true} " \
        "--adjmat_est {input.adjmat_est} " \
        "--filename_data {input.data} " \
        "--filename {output} " \ 
        "--range_header_data 1 " \ 
        "--bdecatpar_chi {wildcards.bdecatpar_chi} " \
        "--bdecatpar_edgepf {wildcards.bdecatpar_edgepf} " \
        " && python scripts/add_column.py --filename {output} --colname replicate   --colval {wildcards.replicate} "\
        " && python scripts/add_column.py --filename {output} --colname algorithm   --colval pcalg "\
        " && python scripts/add_column.py --filename {output} --colname adjmat          --colval {wildcards.adjmat} "  \       
        " && python scripts/add_column.py --filename {output} --colname bn              --colval {wildcards.bn} "  \       
        " && python scripts/add_column.py --filename {output} --colname data            --colval {wildcards.data} "  \       
        " && python scripts/add_column.py --filename {output} --colname alpha       --colval {wildcards.alpha} "\
        " && python scripts/add_column.py --filename {output} --colname score           --colval bde " \
        " && python scripts/add_column.py --filename {output} --colname bdecatpar_chi   --colval {wildcards.bdecatpar_chi} " \
        " && python scripts/add_column.py --filename {output} --colname bdecatpar_edgepf --colval {wildcards.bdecatpar_edgepf} " \    
        " && python scripts/add_column.py --filename {output} --colname fixedGaps   --colval null " \
        " && python scripts/add_column.py --filename {output} --colname fixedEdges  --colval null " \
        " && python scripts/add_column.py --filename {output} --colname NAdelete    --colval true " \
        " && python scripts/add_column.py --filename {output} --colname m.max       --colval inf " \
        " && python scripts/add_column.py --filename {output} --colname conservative --colval false " \
        " && python scripts/add_column.py --filename {output} --colname maj.rule     --colval false " \
        " && python scripts/add_column.py --filename {output} --colname solve.confl  --colval false " \
        " && python scripts/add_column.py --filename {output} --colname numCores     --colval 1 " \
        " && python scripts/add_column.py --filename {output} --colname verbose      --colval false " \
        " && python scripts/add_column.py --filename {output} --colname time          --colval `cat {input.time}` "  \
        " && python scripts/add_column.py --filename {output} --colname legend      --colval {wildcards.plot_legend} "  
            
rule mmhc:
    input:
        data = config["output_dir"]+"/data/{data}/seed={replicate}.csv"
    output:
        adjmat = config["output_dir"]+"/adjmat_estimate/{data}/"\
                "algorithm=/" + pattern_strings["mmhc"] + "/" +\
                "seed={replicate}/" \
                "adjmat.csv",
        time = config["output_dir"] + "/time/{data}/"\
                "algorithm=/" + pattern_strings["mmhc"] + "/" +\
                "seed={replicate}/" \
                "time.txt"
    message:
        "Executing the mmhc algorithm on the following files: {input}."
    shell:
        "/usr/bin/time -f \"%e\" -o {output.time} " \  
        "Rscript scripts/run_mmhc.R "\
        "--filename_data {input.data} "\
        "--alpha {wildcards.alpha} "\
        "--output_dir {config[output_dir]} "\
        "--seed {wildcards.replicate} "\
        "--filename {output.adjmat} "\

rule summarise_mmhc:
    input:
        data = config["output_dir"]+"/data/adjmat=/{adjmat}/bn=/{bn}/data=/{data}/seed={replicate}.csv", 
        adjmat_true = config["output_dir"]+"/adjmat/{adjmat}.csv", 
        adjmat_est =  config["output_dir"]+"/adjmat_estimate/"\
                        "adjmat=/{adjmat}/"\
                        "bn=/{bn}/"\
                        "data=/{data}/"\
                        "algorithm=/" + pattern_strings["mmhc"] + "/" +\
                        "seed={replicate}/" \
                        "adjmat.csv",
        time = config["output_dir"]+"/time/"\
                    "adjmat=/{adjmat}/"\
                    "bn=/{bn}/"\
                    "data=/{data}/" \ 
                    "algorithm=/" + pattern_strings["mmhc"] + "/" +\
                    "seed={replicate}/" \
                    "time.txt",
    output:
        res = config["output_dir"]+"/result/"\
            "algorithm=/" + pattern_strings["mmhc"] + "/" + \
            "adjmat=/{adjmat}/"\
            "bn=/{bn}/"\
            "data=/{data}/"\
            "seed={replicate}/" \
            "legend={plot_legend}/" \        
            "result.csv",
    shell:
        "Rscript scripts/run_summarise.R " \
        "--adjmat_true {input.adjmat_true} " \
        "--adjmat_est {input.adjmat_est} " \
        "--filename_data {input.data} " \
        "--filename {output} " \ 
        "--range_header_data 1 " \ 
        "--bdecatpar_chi {wildcards.bdecatpar_chi} " \
        "--bdecatpar_edgepf {wildcards.bdecatpar_edgepf} " \
        " && python scripts/add_column.py --filename {output} --colname replicate   --colval {wildcards.replicate} "\
        " && python scripts/add_column.py --filename {output} --colname algorithm   --colval mmhc "\
        " && python scripts/add_column.py --filename {output} --colname adjmat          --colval {wildcards.adjmat} "  \       
        " && python scripts/add_column.py --filename {output} --colname bn              --colval {wildcards.bn} "  \       
        " && python scripts/add_column.py --filename {output} --colname data            --colval {wildcards.data} "  \       
        " && python scripts/add_column.py --filename {output} --colname score           --colval bde " \
        " && python scripts/add_column.py --filename {output} --colname bdecatpar_chi   --colval {wildcards.bdecatpar_chi} " \
        " && python scripts/add_column.py --filename {output} --colname bdecatpar_edgepf --colval {wildcards.bdecatpar_edgepf} " \
        " && python scripts/add_column.py --filename {output} --colname alpha       --colval {wildcards.alpha} " \
        " && python scripts/add_column.py --filename {output} --colname whitelist   --colval null " \
        " && python scripts/add_column.py --filename {output} --colname debug       --colval false " \
        " && python scripts/add_column.py --filename {output} --colname maximize.args   --colval null " \
        " && python scripts/add_column.py --filename {output} --colname time          --colval `cat {input.time}` " \
        " && python scripts/add_column.py --filename {output} --colname legend      --colval {wildcards.plot_legend} "  

rule gobnilp:
    input:
        data = config["output_dir"]+"/data/{data}/seed={replicate}.csv"
    output:
        adjmat = config["output_dir"]+"/adjmat_estimate/{data}/"\
                "algorithm=/" + pattern_strings["gobnilp"] + "/" +\
                "seed={replicate}/" \
                "adjmat.csv",
        time = config["output_dir"] + "/time/{data}/"\
                "algorithm=/" + pattern_strings["gobnilp"] + "/" +\
                "seed={replicate}/" \
                "time.txt"
    singularity:
        "docker://onceltuca/gobnilp:1.6.3"
    shell: 
        "touch {output.adjmat}.gobnilp.set && " \   
        "echo 'gobnilp/outputfile/adjacencymatrix = \"{output.adjmat}.bn.mat\" ' > {output.adjmat}.gobnilp.set &&" \
        "echo 'gobnilp/outputfile/scoreandtime = \"score_and_time.txt\" ' >> {output.adjmat}.gobnilp.set &&" \
        "echo 'gobnilp/scoring/palim = {wildcards.palim} ' >> {output.adjmat}.gobnilp.set && " \     
        "echo 'gobnilp/scoring/alpha = {wildcards.alpha} ' >> {output.adjmat}.gobnilp.set && " \
        "echo 'gobnilp/scoring/prune = {wildcards.prune} ' >> {output.adjmat}.gobnilp.set && " \     
        "/myappdir/gobnilp163/bin/gobnilp -f=dat -g={output.adjmat}.gobnilp.set {input.data} " \
        " && cat {output.adjmat}.bn.mat > {output.adjmat} " \
        " && cat score_and_time.txt > {output.time} " \
        " && rm {output.adjmat}.bn.mat " \
        " && rm score_and_time.txt " \
        " && rm {output.adjmat}.gobnilp.set"

rule summarise_gobnilp:
    input:
        data = config["output_dir"]+"/data/adjmat=/{adjmat}/bn=/{bn}/data=/{data}/seed={replicate}.csv", 
        adjmat_true = config["output_dir"]+"/adjmat/{adjmat}.csv",
        adjmat_est =  config["output_dir"]+"/adjmat_estimate/"\
                        "adjmat=/{adjmat}/"\
                        "bn=/{bn}/"\
                        "data=/{data}/"\
                        "algorithm=/" + pattern_strings["gobnilp"] + "/" +\
                        "seed={replicate}/" \
                        "adjmat.csv",
        time = config["output_dir"]+"/time/"\
                    "adjmat=/{adjmat}/"\
                    "bn=/{bn}/"\
                    "data=/{data}/" \ 
                    "algorithm=/" + pattern_strings["gobnilp"] + "/" +\
                    "seed={replicate}/" \
                    "time.txt"
    output:
        res = config["output_dir"]+"/result/"\
            "algorithm=/" + pattern_strings["gobnilp"] + "/" + \
            "adjmat=/{adjmat}/"\
            "bn=/{bn}/"\
            "data=/{data}/"\
            "seed={replicate}/" \
            "legend={plot_legend}/" \        
            "result.csv",
    shell:
        "Rscript scripts/run_summarise.R " \
        "--adjmat_true {input.adjmat_true} " \
        "--adjmat_est {input.adjmat_est} " \
        "--filename_data {input.data} " \
        "--filename {output.res} " \ 
        "--range_header_data 1 " \ 
        "--adjmat_header 0 " \ 
        "--bdecatpar_chi {wildcards.bdecatpar_chi} " \
        "--bdecatpar_edgepf {wildcards.bdecatpar_edgepf} " \
        " && python scripts/add_column.py --filename {output} --colname replicate   --colval {wildcards.replicate} "\
        " && python scripts/add_column.py --filename {output} --colname algorithm   --colval gobnilp "\
        " && python scripts/add_column.py --filename {output} --colname adjmat          --colval {wildcards.adjmat} "  \       
        " && python scripts/add_column.py --filename {output} --colname bn              --colval {wildcards.bn} "  \       
        " && python scripts/add_column.py --filename {output} --colname data            --colval {wildcards.data} "  \
        " && python scripts/add_column.py --filename {output} --colname score           --colval bde " \
        " && python scripts/add_column.py --filename {output} --colname bdecatpar_chi   --colval {wildcards.bdecatpar_chi} " \
        " && python scripts/add_column.py --filename {output} --colname bdecatpar_edgepf --colval {wildcards.bdecatpar_edgepf} " \
        " && python scripts/add_column.py --filename {output} --colname palim       --colval {wildcards.palim} "\
        " && python scripts/add_column.py --filename {output} --colname alpha       --colval {wildcards.alpha} "\
        " && python scripts/add_column.py --filename {output} --colname prune       --colval {wildcards.prune} "\
        " && python scripts/add_column.py --filename {output} --colname time        --colval `cat {input.time} | grep -Eo '[0-9]\.[0-9]*$'` " \
        " && python scripts/add_column.py --filename {output} --colname legend      --colval {wildcards.plot_legend} "  

rule fges:
    input:
        data = config["output_dir"]+"/data/{data}/seed={replicate}.csv"
    output:
        adjmat = config["output_dir"]+"/adjmat_estimate/{data}/"\
                "algorithm=/" + pattern_strings["fges"] + "/" +\
                "seed={replicate}/" \
                "adjmat.csv",
        time = config["output_dir"] + "/time/{data}/"\
                "algorithm=/" + pattern_strings["fges"] + "/" +\
                "seed={replicate}/" \
                "time.txt"
    message:
        "Executing fges algorithm on the following files: {input}."
    shell:
        "/usr/bin/time -f \"%e\" -o {output.time} " \  
        "java -jar causal-cmd-1.1.3-jar-with-dependencies.jar " \
        "--algorithm fges "\
        "--data-type {wildcards.datatype} "\
        "--dataset {input.data} "\
        "--delimiter space " # TODO: This might read the header as well \
        "--score {wildcards.score} "\
        "--json-graph "\
        "--structurePrior 1 "\
        "--prefix {output.adjmat} " \
        '&& Rscript scripts/tetrad_graph_to_adjmat.R ' \
        '--jsongraph {output.adjmat}_graph.json ' \
        '--filename {output.adjmat} ' \
        '&& ' \
        'rm {output.adjmat}_graph.json ' \
        '&& ' \
        'rm {output.adjmat}.txt'

rule summarise_fges:
    input:
        data = config["output_dir"]+"/data/adjmat=/{adjmat}/bn=/{bn}/data=/{data}/seed={replicate}.csv", 
        adjmat_true = config["output_dir"]+"/adjmat/{adjmat}.csv",
        adjmat_est =  config["output_dir"]+"/adjmat_estimate/"\
                        "adjmat=/{adjmat}/"\
                        "bn=/{bn}/"\
                        "data=/{data}/"\
                        "algorithm=/" + pattern_strings["fges"] + "/" +
                        "seed={replicate}/" \
                        "adjmat.csv",
        time = config["output_dir"]+"/time/"\
                    "adjmat=/{adjmat}/"\
                    "bn=/{bn}/"\
                    "data=/{data}/" \ 
                    "algorithm=/" + pattern_strings["fges"] + "/" +
                    "seed={replicate}/" \
                    "time.txt",
    output:
        res = config["output_dir"]+"/result/"\
            "algorithm=/" + pattern_strings["fges"] + "/" +
            "adjmat=/{adjmat}/"\
            "bn=/{bn}/"\
            "data=/{data}/"\
            "seed={replicate}/" \
            "legend={plot_legend}/" \        
            "result.csv",
    message:
        "Summarising fges results based on the files: {input}."
    shell:
        "Rscript scripts/run_summarise.R " \
        "--adjmat_true {input.adjmat_true} " \
        "--adjmat_est {input.adjmat_est} " \
        "--filename_data {input.data} " \
        "--filename {output.res} " \ 
        "--range_header_data 1 " \ 
        "--bdecatpar_chi {wildcards.bdecatpar_chi} " \
        "--bdecatpar_edgepf {wildcards.bdecatpar_edgepf} " \        
        " && python scripts/add_column.py --filename {output} --colname replicate   --colval {wildcards.replicate} "\
        " && python scripts/add_column.py --filename {output} --colname algorithm   --colval fges "\
        " && python scripts/add_column.py --filename {output} --colname score           --colval bde " \
        " && python scripts/add_column.py --filename {output} --colname adjmat           --colval {wildcards.adjmat} " \
        " && python scripts/add_column.py --filename {output} --colname bn              --colval {wildcards.bn} " \
        " && python scripts/add_column.py --filename {output} --colname data           --colval {wildcards.data} " \
        " && python scripts/add_column.py --filename {output} --colname score           --colval bde " \
        " && python scripts/add_column.py --filename {output} --colname bdecatpar_chi   --colval {wildcards.bdecatpar_chi} " \
        " && python scripts/add_column.py --filename {output} --colname bdecatpar_edgepf --colval {wildcards.bdecatpar_edgepf} " \
        " && python scripts/add_column.py --filename {output} --colname faithfulnessAssumed       --colval {wildcards.faithfulnessAssumed} "\
        " && python scripts/add_column.py --filename {output} --colname time        --colval `cat {input.time}` " \
        " && python scripts/add_column.py --filename {output} --colname legend      --colval {wildcards.plot_legend} "  
        
rule join_summaries_blip:
    input:
        conf="config.json",
        res=[[[[expand(config["output_dir"] + "/result/"\
        "algorithm=/"
        "{alg_string}/" 
        "adjmat=/"
        "{adjmat_string}/"
        "bn=/"\
        "{param_string}/"
        "data=/"
        "n={n}/"
        "seed={replicate}/"
        "legend={plot_legend}/" 
        "result.csv"
        ,
        replicate=seed,
        alg_string=json_string[alg_conf_key],
        n=config["data"]["sample_sizes"][i], 
        plot_legend=alg_conf["plot_legend"],
        adjmat_string=gen_adjmat_string_from_conf(config["plotting"]["models"][j]["graph"], seed, i), 
        param_string=gen_parameter_string_from_conf(config["plotting"]["models"][j]["parameters"], seed)
        )
        for seed in replicates] 
        for i in range(len(config["data"]["sample_sizes"]))]
        for j in range(len(config["plotting"]["models"]))]
        for alg_conf_key, alg_conf in config["algorithms"]["blip"].items() if alg_conf_key in config["plotting"]["algorithms"]],
        fixed_res = [[expand(config["output_dir"] + "/result/"\        
                        "algorithm=/"
                        "{alg_string}/"
                        "adjmat=/"
                        "{adjmat_string}/"
                        "bn=/"\
                        "{param_string}/"
                        "data=/"
                        "generation_method=fixed/" #or standard_Sampling                        
                        "name={filename}/"
                        "n={n}/"
                        "seed={replicate}/"
                        "legend={plot_legend}/" 
                        "result.csv",
                        replicate=1,
                        alg_string=json_string[alg_conf_key],
                        n=None,
                        plot_legend=alg_conf["plot_legend"],
                        adjmat_string="myadjmats/" + config["plotting"]["fixed_data"][j]["graph"],
                        param_string=None, 
                        filename=config["plotting"]["fixed_data"][j]["data"],
        )         
        for j in range(len(config["plotting"]["fixed_data"]))]
        for alg_conf_key, alg_conf in config["algorithms"]["blip"].items() if alg_conf_key in config["plotting"]["algorithms"]],
    output:
        config["output_dir"] + "/blip.csv"
    shell:
        "Rscript scripts/join_csv_files.R --algorithm blip --filename {output} --files {input.res} {input.fixed_res} "
        " && sed --in-place 's/\/seed=[0-9]\+//g' {output}" # removes the /seed={seed} :-)
        
rule join_summaries_itsearch:
    input:
        conf="config.json",
        res=[[[[expand(config["output_dir"] + "/result/"\        
                        "algorithm=/"
                        "{alg_string}/"
                        "adjmat=/"
                        "{adjmat_string}/"
                        "bn=/"\
                        "{param_string}/"
                        "data=/"
                        "n={n}/"
                        "seed={replicate}/"
                        "legend={plot_legend}/" 
                        "result.csv",
                        replicate=seed,
                        alg_string=json_string[alg_conf_key],
                        n=config["data"]["sample_sizes"][i],
                        plot_legend=alg_conf["plot_legend"],
                        adjmat_string=gen_adjmat_string_from_conf(config["plotting"]["models"][j]["graph"], seed, i), 
                        param_string=gen_parameter_string_from_conf(config["plotting"]["models"][j]["parameters"], seed)
        )         
        for seed in replicates] 
        for i in range(len(config["data"]["sample_sizes"]))]
        for j in range(len(config["plotting"]["models"]))]
        for alg_conf_key, alg_conf in config["algorithms"]["itsearch"].items() if alg_conf_key in config["plotting"]["algorithms"]],
        fixed_res = [[expand(config["output_dir"] + "/result/"\        
                        "algorithm=/{alg_string}/"
                        "adjmat=/{adjmat_string}/"
                        "bn=/{param_string}/"
                        "data=/"
                        "generation_method=fixed/" #or standard_Sampling                        
                        "name={filename}/"
                        "n={n}/"
                        "seed={replicate}/"
                        "legend={plot_legend}/" 
                        "result.csv",
                        replicate=1,                        
                        alg_string=json_string[key],
                        n=None,
                        plot_legend=alg_conf["plot_legend"],
                        adjmat_string="myadjmats/" + config["plotting"]["fixed_data"][j]["graph"],
                        param_string=None, 
                        filename=config["plotting"]["fixed_data"][j]["data"],
        )         
        for j in range(len(config["plotting"]["fixed_data"]))]
        for key, alg_conf in config["algorithms"]["itsearch"].items() if key in config["plotting"]["algorithms"]],
    output:
        config["output_dir"] + "/itsearch.csv"
    shell:
        "Rscript scripts/join_csv_files.R --algorithm itsearch --filename {output} --files {input.res} {input.fixed_res}"
        " && sed --in-place 's/\/seed=[0-9]\+//g' {output}" # removes the /seed={seed} :-)

# create to string method for algorithms in json files
rule join_summaries_order_mcmc:
    input: # should save the database and give id. then startspace would have been an id instead.
           # How would we know that id...?
        conf="config.json",
        res=[[[[expand(config["output_dir"] + "/result/"\        
                        "algorithm=/{json_string}/" + pattern_strings["mcmc_est"] + "/" + 
                        "adjmat=/{adjmat_string}/"
                        "bn=/{param_string}/"
                        "data=/"
                        "n={n}/"
                        "seed={replicate}/"
                        "legend={plot_legend}/" 
                        "result.csv",
        replicate=seed,   
        n=config["data"]["sample_sizes"][i],
        threshold=alg_conf["threshold"],
        burnin=alg_conf["burnin"],        
        json_string=json_string[key],
        plot_legend=alg_conf["plot_legend"], 
        adjmat_string=gen_adjmat_string_from_conf(config["plotting"]["models"][j]["graph"], seed, i), 
        param_string=gen_parameter_string_from_conf(config["plotting"]["models"][j]["parameters"], seed)
        )         
        for seed in replicates] 
        for i in range(len(config["data"]["sample_sizes"]))]
        for j in range(len(config["plotting"]["models"]))]
        for key, alg_conf in config["algorithms"]["order_mcmc"].items() if key in config["plotting"]["algorithms"]],
        fixed_res = [[expand(config["output_dir"] + "/result/"\        
                        "algorithm=/{json_string}/" + pattern_strings["mcmc_est"] + 
                        "adjmat=/"
                        "{adjmat_string}/"
                        "bn=/"\
                        "{param_string}/"
                        "data=/"
                        "generation_method=fixed/" # or standard_Sampling                        
                        "name={filename}/"
                        "n={n}/"
                        "seed={replicate}/"
                        "legend={plot_legend}/" 
                        "result.csv",
                        replicate=1,                        
                        threshold=alg_conf["threshold"],
                        burnin=alg_conf["burnin"],
                        n=None,
                        json_string=json_string[key],
                        plot_legend=alg_conf["plot_legend"],
                        adjmat_string="myadjmats/" + config["plotting"]["fixed_data"][j]["graph"],
                        param_string=None, 
                        filename=config["plotting"]["fixed_data"][j]["data"],
        )         
        for j in range(len(config["plotting"]["fixed_data"]))]
        for key, alg_conf in config["algorithms"]["order_mcmc"].items() if key in config["plotting"]["algorithms"]],
    output:
        config["output_dir"] + "/order_mcmc.csv"
    shell:
        "Rscript scripts/join_csv_files.R --algorithm order_mcmc --filename {output} --files {input.res} {input.fixed_res}"
        " && sed --in-place 's/\/seed=[0-9]\+//g' {output}" # removes the /seed={seed} :-)

rule join_summaries_trilearn_loglin:
    input: # should save the database and give id. then startspace would have been an id instead.
           # How would we know that id...?
        conf="config.json",
        res=[[[[expand(config["output_dir"] + "/result/"\        
                        "algorithm=/"
                        "{alg_string}/"
                        + pattern_strings["mcmc_est"]  + "/" + 
                        "adjmat=/{adjmat_string}/"
                        "bn=/{param_string}/"
                        "data=/"
                        "n={n}/"
                        "seed={replicate}/"
                        "legend={plot_legend}/" 
                        "result.csv",
        replicate=seed,   
        n=config["data"]["sample_sizes"][i],
        threshold=alg_conf["threshold"],
        burnin=alg_conf["burnin"],
        alg_string=json_string[key],
        plot_legend=alg_conf["plot_legend"], 
        adjmat_string=gen_adjmat_string_from_conf(config["plotting"]["models"][j]["graph"], seed, i), 
        param_string=gen_parameter_string_from_conf(config["plotting"]["models"][j]["parameters"], seed)
        )         
        for seed in replicates] 
        for i in range(len(config["data"]["sample_sizes"]))]
        for j in range(len(config["plotting"]["models"]))]
        for key, alg_conf in config["algorithms"]["trilearn_loglin"].items() if key in config["plotting"]["algorithms"]],
        fixed_res = [[expand(config["output_dir"] + "/result/"\        
                        "algorithm=/"\
                        "{alg_string}/" + 
                        pattern_strings["mcmc_est"] + "/" +
                        "adjmat=/"
                        "{adjmat_string}/"
                        "bn=/"\
                        "{param_string}/"
                        "data=/"
                        "generation_method=fixed/" # or standard_Sampling                        
                        "name={filename}/"
                        "n={n}/"
                        "seed={replicate}/"
                        "legend={plot_legend}/" 
                        "result.csv",
                        replicate=1,                        
                        threshold=alg_conf["threshold"],
                        burnin=alg_conf["burnin"],
                        alg_string=json_string[key],
                        n=None,
                        plot_legend=alg_conf["plot_legend"],
                        adjmat_string="myadjmats/" + config["plotting"]["fixed_data"][j]["graph"],
                        param_string=None, 
                        filename=config["plotting"]["fixed_data"][j]["data"],
        )         
        for j in range(len(config["plotting"]["fixed_data"]))]
        for key, alg_conf in config["algorithms"]["trilearn_loglin"].items() if key in config["plotting"]["algorithms"]],
    output:
        config["output_dir"] + "/trilearn_loglin.csv"
    shell:
        "Rscript scripts/join_csv_files.R --algorithm trilearn_loglin --filename {output} --files {input.res} {input.fixed_res}"
        " && sed --in-place 's/\/seed=[0-9]\+//g' {output}" # removes the /seed={seed} :-)

rule join_summaries_pcalg:
    input:
        conf="config.json",
        res=[[[[expand(config["output_dir"] + "/result/"\        
                        "algorithm=/"
                        "{alg_string}/" +
                        "adjmat=/"
                        "{adjmat_string}/"
                        "bn=/"\
                        "{param_string}/"
                        "data=/"
                        "n={n}/"
                        "seed={replicate}/"
                        "legend={plot_legend}/" 
                        "result.csv",
                        replicate=seed,
                        alg_string=json_string[key],
                        n=config["data"]["sample_sizes"][i],
                        plot_legend=alg_conf["plot_legend"],
                        adjmat_string=gen_adjmat_string_from_conf(config["plotting"]["models"][j]["graph"], seed, i), 
                        param_string=gen_parameter_string_from_conf(config["plotting"]["models"][j]["parameters"], seed)
        )         
        for seed in replicates] 
        for i in range(len(config["data"]["sample_sizes"]))]
        for j in range(len(config["plotting"]["models"]))]
        for key, alg_conf in config["algorithms"]["pcalg"].items() if key in config["plotting"]["algorithms"]]
        ,
        fixed_res = [[expand(config["output_dir"] + "/result/"\        
                        "algorithm=/"
                        "{alg_string}/" +
                        "adjmat=/"
                        "{adjmat_string}/"
                        "bn=/"\
                        "{param_string}/"
                        "data=/"
                        "generation_method=fixed/" #or standard_Sampling                        
                        "name={filename}/"
                        "n={n}/"
                        "seed={replicate}/"
                        "legend={plot_legend}/" 
                        "result.csv",
                        replicate=1,
                        alg_string=json_string[key],
                        n=None,
                        plot_legend=alg_conf["plot_legend"],
                        adjmat_string="myadjmats/" + config["plotting"]["fixed_data"][j]["graph"],
                        param_string=None, 
                        filename=config["plotting"]["fixed_data"][j]["data"],
        )         
        for j in range(len(config["plotting"]["fixed_data"]))]
        for key, alg_conf in config["algorithms"]["pcalg"].items() if key in config["plotting"]["algorithms"]],
    output:
        config["output_dir"] + "/pcalg.csv"
    shell:
        "Rscript scripts/join_csv_files.R --algorithm pcalg --filename {output} --files {input.res} {input.fixed_res}"
        " && sed --in-place 's/\/seed=[0-9]\+//g' {output}" # removes the /seed={seed} :-)

rule join_summaries_tabu:
    input:
        conf="config.json",
        res=[[[[expand(config["output_dir"] + "/result/"\        
                        "algorithm=/"
                        "{alg_string}/"
                        "adjmat=/"
                        "{adjmat_string}/"
                        "bn=/"\
                        "{param_string}/"
                        "data=/"
                        "n={n}/"
                        "seed={replicate}/"
                        "legend={plot_legend}/" 
                        "result.csv",
                        replicate=seed,
                        alg_string=json_string[key],
                        n=config["data"]["sample_sizes"][i],
                        plot_legend=alg_conf["plot_legend"],
                        adjmat_string=gen_adjmat_string_from_conf(config["plotting"]["models"][j]["graph"], seed, i), 
                        param_string=gen_parameter_string_from_conf(config["plotting"]["models"][j]["parameters"], seed)
        )         
        for seed in replicates] 
        for i in range(len(config["data"]["sample_sizes"]))]
        for j in range(len(config["plotting"]["models"]))]
        for key, alg_conf in config["algorithms"]["tabu"].items() if key in config["plotting"]["algorithms"]]
        ,
        fixed_res = [[expand(config["output_dir"] + "/result/"\        
                        "algorithm=/"
                        "{alg_string}/"
                        "adjmat=/"
                        "{adjmat_string}/"
                        "bn=/"\
                        "{param_string}/"
                        "data=/"
                        "generation_method=fixed/" #or standard_Sampling                        
                        "name={filename}/"
                        "n={n}/"
                        "seed={replicate}/"
                        "legend={plot_legend}/" 
                        "result.csv",
                        replicate=1,
                        alg_string=json_string[key],
                        n=None,
                        plot_legend=alg_conf["plot_legend"],
                        adjmat_string="myadjmats/" + config["plotting"]["fixed_data"][j]["graph"],
                        param_string=None, 
                        filename=config["plotting"]["fixed_data"][j]["data"],
        )         
        for j in range(len(config["plotting"]["fixed_data"]))]
        for key, alg_conf in config["algorithms"]["tabu"].items() if key in config["plotting"]["algorithms"]],
    output:
        config["output_dir"] + "/tabu.csv"
    shell:
        "Rscript scripts/join_csv_files.R --algorithm tabu --filename {output} --files {input.res} {input.fixed_res}"
        " && sed --in-place 's/\/seed=[0-9]\+//g' {output}" # removes the /seed={seed} :-)

rule join_summaries_mmhc:
    input:
        conf="config.json",
        res=[[[[expand(config["output_dir"] + "/result/"\        
                        "algorithm=/"
                        "{alg_string}/"
                        #+ pattern_strings["mmhc"] + "/" +
                        "adjmat=/"
                        "{adjmat_string}/"
                        "bn=/"\
                        "{param_string}/"
                        "data=/"
                        "n={n}/"
                        "seed={replicate}/"
                        "legend={plot_legend}/" 
                        "result.csv",
                        replicate=seed,
                        alg_string=json_string[key],
                        #alpha=alg_conf["restrict.args"]["alpha"],
                        n=config["data"]["sample_sizes"][i],
                        #score_type="bde",
                        #bdecatpar_chi=config["evaluation"]["score"]["bdecatpar"]["chi"],
                        #bdecatpar_edgepf=config["evaluation"]["score"]["bdecatpar"]["edgepf"],
                        plot_legend=alg_conf["plot_legend"],
                        adjmat_string=gen_adjmat_string_from_conf(config["plotting"]["models"][j]["graph"], seed, i), 
                        param_string=gen_parameter_string_from_conf(config["plotting"]["models"][j]["parameters"], seed)
        )         
        for seed in replicates] 
        for i in range(len(config["data"]["sample_sizes"]))]
        for j in range(len(config["plotting"]["models"]))]
        for key, alg_conf in config["algorithms"]["mmhc"].items() if key in config["plotting"]["algorithms"]],
        fixed_res = [[expand(config["output_dir"] + "/result/"\        
                        "algorithm=/"
                        "{alg_string}/"
                        #+ pattern_strings["mmhc"] + "/" +
                        "adjmat=/"
                        "{adjmat_string}/"
                        "bn=/"\
                        "{param_string}/"
                        "data=/"
                        "generation_method=fixed/" #or standard_Sampling                        
                        "name={filename}/"
                        "n={n}/"
                        "seed={replicate}/"
                        "legend={plot_legend}/" 
                        "result.csv",
                        replicate=1,
                        alg_string=json_string[key],
                        #alpha=alg_conf["restrict.args"]["alpha"],
                        n=None,
                        score_type="bde",
                        bdecatpar_chi=config["evaluation"]["score"]["bdecatpar"]["chi"],
                        bdecatpar_edgepf=config["evaluation"]["score"]["bdecatpar"]["edgepf"],
                        plot_legend=alg_conf["plot_legend"],
                        adjmat_string="myadjmats/" + config["plotting"]["fixed_data"][j]["graph"],
                        param_string=None, 
                        filename=config["plotting"]["fixed_data"][j]["data"],
        )         
        for j in range(len(config["plotting"]["fixed_data"]))]
        for key, alg_conf in config["algorithms"]["mmhc"].items() if key in config["plotting"]["algorithms"]],
    output:
        config["output_dir"] + "/mmhc.csv"
    shell:
        "Rscript scripts/join_csv_files.R --algorithm mmhc --filename {output} --files {input.res} {input.fixed_res}"
        " && sed --in-place 's/\/seed=[0-9]\+//g' {output}" # removes the /seed={seed} :-)

rule join_summaries_gobnilp:
    input:
        conf="config.json",
        res=[[[[expand(config["output_dir"] + "/result/"\        
                        "algorithm=/"
                        "{alg_string}/"
                        #+ pattern_strings["gobnilp"] + "/" +
                        "adjmat=/"
                        "{adjmat_string}/"
                        "bn=/"\
                        "{param_string}/"
                        "data=/"
                        "n={n}/"
                        "seed={replicate}/"
                        "legend={plot_legend}/" 
                        "result.csv",
                        replicate=seed,      
                        alg_string=json_string[key],                  
                        #palim=alg_conf["palim"],
                        n=config["data"]["sample_sizes"][i],
                        #score_type="bde",
                        #bdecatpar_chi=config["evaluation"]["score"]["bdecatpar"]["chi"],
                        #bdecatpar_edgepf=config["evaluation"]["score"]["bdecatpar"]["edgepf"],
                        plot_legend=alg_conf["plot_legend"],
                        adjmat_string=gen_adjmat_string_from_conf(config["plotting"]["models"][j]["graph"], seed, i), 
                        param_string=gen_parameter_string_from_conf(config["plotting"]["models"][j]["parameters"], seed)
        )         
        for seed in replicates] 
        for i in range(len(config["data"]["sample_sizes"]))]
        for j in range(len(config["plotting"]["models"]))]
        for key, alg_conf in config["algorithms"]["gobnilp"].items() if key in config["plotting"]["algorithms"]],
        fixed_res = [[expand(config["output_dir"] + "/result/"\        
                        "algorithm=/"
                        "{alg_string}/"
                        "adjmat=/"
                        "{adjmat_string}/"
                        "bn=/"\
                        "{param_string}/"
                        "data=/"
                        "generation_method=fixed/" #or standard_Sampling                        
                        "name={filename}/"
                        "n={n}/"
                        "seed={replicate}/"
                        "legend={plot_legend}/" 
                        "result.csv",
                        replicate=1,
                        alg_string=json_string[key],                  
                        n=None,
                        plot_legend=alg_conf["plot_legend"],
                        adjmat_string="myadjmats/" + config["plotting"]["fixed_data"][j]["graph"],
                        param_string=None, 
                        filename=config["plotting"]["fixed_data"][j]["data"],
        )         
        for j in range(len(config["plotting"]["fixed_data"]))]
        for key, alg_conf in config["algorithms"]["gobnilp"].items() if key in config["plotting"]["algorithms"]],

    output:
        config["output_dir"] + "/gobnilp.csv"
    shell:
        "Rscript scripts/join_csv_files.R --algorithm gobnilp --filename {output} --files {input.res} {input.fixed_res} "
        " && sed --in-place 's/\/seed=[0-9]\+//g' {output}" # removes the /seed={seed} :-)

rule join_summaries_fges:
    input: # This could be a funciton since no pattern mathing is going on here
        conf="config.json",
        res=[[[[expand(config["output_dir"] + "/result/"\        
                        "algorithm=/"
                        "{alg_string}/"
                        "adjmat=/"
                        "{adjmat_string}/"
                        "bn=/"\
                        "{param_string}/"
                        "data=/"
                        "n={n}/"
                        "seed={replicate}/"
                        "legend={plot_legend}/" 
                        "result.csv",
                        replicate=seed,
                        alg_string=json_string[key],
                        n=config["data"]["sample_sizes"][i],
                        plot_legend=alg_conf["plot_legend"],
                        adjmat_string=gen_adjmat_string_from_conf(config["plotting"]["models"][j]["graph"], seed, i), 
                        param_string=gen_parameter_string_from_conf(config["plotting"]["models"][j]["parameters"], seed)
        )         
        for seed in replicates] 
        for i in range(len(config["data"]["sample_sizes"]))]
        for j in range(len(config["plotting"]["models"]))]
        for key, alg_conf in config["algorithms"]["fges"].items() if key in config["plotting"]["algorithms"]],
        fixed_res = [[expand(config["output_dir"] + "/result/"\        
                        "algorithm=/"
                        "{alg_string}/"
                        "adjmat=/"
                        "{adjmat_string}/"
                        "bn=/"\
                        "{param_string}/"
                        "data=/"
                        "generation_method=fixed/" #or standard_Sampling                        
                        "name={filename}/"
                        "n={n}/"
                        "seed={replicate}/"
                        "legend={plot_legend}/" 
                        "result.csv",
                        replicate=1,
                        alg_string=json_string[key],
                        n=None,
                        plot_legend=alg_conf["plot_legend"],
                        adjmat_string="myadjmats/" + config["plotting"]["fixed_data"][j]["graph"],
                        param_string=None, 
                        filename=config["plotting"]["fixed_data"][j]["data"],
        )         
        for j in range(len(config["plotting"]["fixed_data"]))]
        for key, alg_conf in config["algorithms"]["fges"].items() if key in config["plotting"]["algorithms"]],

    output:
        config["output_dir"] + "/fges.csv"
    shell:
        "Rscript scripts/join_csv_files.R --algorithm fges --filename {output} --files {input.res} {input.fixed_res}"
        " && sed --in-place 's/\/seed=[0-9]\+//g' {output}" # removes the /seed={seed} :-)

# This should be different for mcmc algorithms for example
# def join_csv_files(wildcards):
#     alg = wildcards.alg
#     conf="config.json",
#     res=[[[[expand(config["output_dir"] + "/result/"\        
#                         "algorithm=/"
#                         "{alg_string}/"
#                         "adjmat=/"
#                         "{adjmat_string}/"
#                         "bn=/"\
#                         "{param_string}/"
#                         "data=/"
#                         "n={n}/"
#                         "seed={replicate}/"
#                         "legend={plot_legend}/" 
#                         "result.csv",
#                         replicate=seed,
#                         alg_string=json_string[key],
#                         n=config["data"]["sample_sizes"][i],
#                         plot_legend=alg_conf["plot_legend"],
#                         adjmat_string=gen_adjmat_string_from_conf(config["plotting"]["models"][j]["graph"], seed, i), 
#                         param_string=gen_parameter_string_from_conf(config["plotting"]["models"][j]["parameters"], seed)
#         )         
#         for seed in replicates] 
#         for i in range(len(config["data"]["sample_sizes"]))]
#         for j in range(len(config["plotting"]["models"]))]
#         for key, alg_conf in config["algorithms"][alg].items() if key in config["plotting"]["algorithms"]],
#     fixed_res = [[expand(config["output_dir"] + "/result/"\        
#                         "algorithm=/"
#                         "{alg_string}/"
#                         "adjmat=/"
#                         "{adjmat_string}/"
#                         "bn=/"\
#                         "{param_string}/"
#                         "data=/"
#                         "generation_method=fixed/" #or standard_Sampling                        
#                         "name={filename}/"
#                         "n={n}/"
#                         "seed={replicate}/"
#                         "legend={plot_legend}/" 
#                         "result.csv",
#                         replicate=1,
#                         alg_string=json_string[key],
#                         n=None,
#                         plot_legend=alg_conf["plot_legend"],
#                         adjmat_string="myadjmats/" + config["plotting"]["fixed_data"][j]["graph"],
#                         param_string=None, 
#                         filename=config["plotting"]["fixed_data"][j]["data"],
#         )         
#         for j in range(len(config["plotting"]["fixed_data"]))]
#         for key, alg_conf in config["algorithms"][alg].items() if key in config["plotting"]["algorithms"]]

#         return res + fixed_res

#le join_summaries:
#    input:
#        "config.json",
#        join_csv_files
#    output:
#        config["output_dir"] + "/{algorithm}.csv"
#    shell:
#        "Rscript scripts/join_csv_files.R --algorithm {wildcards.algorithm} --filename {output} --files {input.res} {input.fixed_res}"
#        " && sed --in-place 's/\/seed=[0-9]\+//g' {output}" # removes the /seed={seed} :-)

rule roc:
    input:
        "config.json",
        active_algorithm_files
    output:
        config["output_dir"] + "/ROC.eps", \
        config["output_dir"] + "/ROC_data.csv" 
    shell:
        "Rscript scripts/combine_ROC_data.R "\
        "&& Rscript scripts/plot_ROC.R"